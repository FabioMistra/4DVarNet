{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "tJQ0EiFqowZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch_lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgfZhE8jxhiN",
        "outputId": "251c2d0c-a3f4-43d9-cae1-5a8af389d53a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.10.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (0.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch_lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (2.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch_lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch_lightning) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rioxarray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2MgMh8sFGV-",
        "outputId": "aa7dbae7-2e8e-41e0-e4ea-644812ae7b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rioxarray in /usr/local/lib/python3.10/dist-packages (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from rioxarray) (23.2)\n",
            "Requirement already satisfied: rasterio>=1.3 in /usr/local/lib/python3.10/dist-packages (from rioxarray) (1.3.9)\n",
            "Requirement already satisfied: xarray>=2022.3.0 in /usr/local/lib/python3.10/dist-packages (from rioxarray) (2023.7.0)\n",
            "Requirement already satisfied: pyproj>=3.3 in /usr/local/lib/python3.10/dist-packages (from rioxarray) (3.6.1)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from rioxarray) (1.25.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj>=3.3->rioxarray) (2024.2.2)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.3->rioxarray) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.3->rioxarray) (23.2.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.3->rioxarray) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.3->rioxarray) (0.7.2)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.3->rioxarray) (1.4.7)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.3->rioxarray) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.3->rioxarray) (67.7.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from xarray>=2022.3.0->rioxarray) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray>=2022.3.0->rioxarray) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray>=2022.3.0->rioxarray) (2023.4)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio>=1.3->rioxarray) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.4->xarray>=2022.3.0->rioxarray) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import torch.utils.data\n",
        "import functools as ft\n",
        "from tqdm import tqdm\n",
        "from collections import namedtuple\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import copy\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import rioxarray\n"
      ],
      "metadata": {
        "id": "yjCHb0txP892"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB56G95rPGt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee8a201-6afb-4451-afe6-f1ad45611450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the data"
      ],
      "metadata": {
        "id": "x09v5wcwo4lj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## original data from Delft3D"
      ],
      "metadata": {
        "id": "zZhSpHoyYGjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## the unit of the Inorganic Matter (IM) variable is gDM/m3, that means grams of Dry Matter per cubic meter\n",
        "\n",
        "path_surf = '/content/drive/MyDrive/Material for Master thesis/DATA/IM_surface_regul.nc'\n",
        "data_surf = xr.open_dataset(path_surf)\n",
        "data_surf = data_surf.drop_vars([\"mesh2d_layer_sigma\", \"mesh2d_face_x\",\"mesh2d_face_y\", \"mesh2d_nFaces\"])\n",
        "\n",
        "#extracting the variable\n",
        "# data_surf = data_surf.rename({'y': 'lat', 'x': 'lon'})\n",
        "new_value = np.where(data_surf['__xarray_dataarray_variable__'] <= 10**-1, 10**-1, data_surf['__xarray_dataarray_variable__'])  ## removing negative values\n",
        "new_value = np.where(new_value >= 10**4, 10**4, new_value)                                                                      ## removing high values\n",
        "# data_surf['SPM'] = (['time', 'lat', 'lon'], new_value) #np.log10(new_value))\n",
        "data_surf['SPM'] = (['time', 'y', 'x'], np.log10(new_value))                                                                    ## log10 transform\n",
        "\n",
        "y_test = np.load(r'/content/drive/MyDrive/Material for Master thesis/DATA/y_pred.npy')\n"
      ],
      "metadata": {
        "id": "_eSVqqw2P7vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## creating the land mask (without the islands)\n",
        "bool_mask = np.isnan(data_surf['SPM'][5,:,:])\n",
        "mask = np.where(bool_mask == True, np.nan, 1.)\n",
        "plt.imshow(mask, origin = 'lower')\n",
        "plt.colorbar()\n"
      ],
      "metadata": {
        "id": "UD8wRmDrzxvv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "27b6d3ab-9a5d-45b9-94d3-173eb6773584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x79392e76e0e0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAGTCAYAAAD+/cJkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8r0lEQVR4nO3deXRUVb7//U8FzKChkg6EDBIkxAEcCC1DzNM0guRaBJZXMO1yoC8REB78BVZD9HJNdxqQ6/Okm74yqBHsq5JW4KJ0K92CHZ8QJDTXABLNcoQFGAkCFRxWUhDNQOo8f9ApKRMgJ3WSSlHv11pnLWqffU7tOkby5fvde5fNMAxDAAAA3SzE3wMAAADBiSAEAAD4BUEIAADwC4IQAADgFwQhAADALwhCAACAXxCEAAAAvyAIAQAAfkEQAgAA/IIgBAAA+AVBCAAAAWrXrl266667lJiYKJvNpi1btly0/8mTJ/Xggw/q+uuvV0hIiBYsWNBuv82bN2vIkCEKDw/XLbfcorfeesvrvGEYWrx4sRISEhQREaGMjAwdOnTI9PgJQgAACFD19fVKTU1VYWFhh/o3NjYqNjZW+fn5Sk1NbbfPu+++qwceeECzZs3SBx98oClTpmjKlCn6+OOPPX2WL1+up59+WmvXrtXevXt11VVXyeFwqKGhwdT4bXyBHQAAgc9ms+mNN97QlClTOtR/3LhxGj58uFatWuXVft9996m+vl5bt271tN12220aPny41q5dK8MwlJiYqEcffVSPPfaYJKmurk5xcXEqKirS/fff3+Ex9+5wTwAAcEENDQ1qamry+T6GYchms3m1hYWFKSwszOd7d0R5eblyc3O92hwOh6fUU1VVJafTqYyMDM/5qKgopaWlqby8nCAEAIDu1NDQoORrIuU81eLzvSIjI3XmzBmvtiVLlmjp0qU+37sjnE6n4uLivNri4uLkdDo951vbLtSnowhCAADwUVNTk5ynWlRVcY3sfTo/3dJ12q3kEUd17Ngx2e12T3t3ZUG6G0EIAAAWsfcJ8SkI8dzHbvcKQrpTfHy8ampqvNpqamoUHx/vOd/alpCQ4NVn+PDhpt6L1TEAAFikxXD7fPhbenq6SktLvdpKSkqUnp4uSUpOTlZ8fLxXH5fLpb1793r6dBSZEAAALOKWIbc6v+jU7LVnzpzR4cOHPa+rqqpUWVmpmJgYDRw4UHl5eTp+/LhefvllT5/KykrPtV999ZUqKysVGhqqG2+8UZL0q1/9SrfffrueeuopTZ48WZs2bdL+/fv1xz/+UdK5VTgLFizQk08+qeuuu07Jycn67W9/q8TExA6vzGnFEl0AAHzkcrkUFRUl58GBPs8Jib+hWnV1dR0qx+zcuVPjx49v056dna2ioiI99NBD+uKLL7Rz507PuR+vvJGka665Rl988YXn9ebNm5Wfn68vvvhC1113nZYvX65JkyZ5zhuGoSVLluiPf/yjamtrNWbMGD333HO6/vrrTX1eghAAAHzUGoScODjA5yAk8YYvOxyEBDrKMQAAWKTFMNTiw7/tfbk2EDExFQAA+AWZEAAALNLdE1MDHUEIAAAWcctQC0FIhxGEAABgETIh5jAnBAAA+AWZEAAALMLqGHMIQgAAsIj7n4cv1wcTyjEAAMAvyIQAAGCRFh9Xx/hybSAiCAEAwCItxrnDl+uDCeUYAADgF2RCAACwCBNTzSEIAQDAIm7Z1CKbT9cHE8oxAADAL8iEAABgEbdx7vDl+mBCEAIAgEVafCzH+HJtICIIAQDAIgQh5jAnBAAA+AWZEAAALOI2bHIbPqyO8eHaQEQQAgCARSjHmEM5BgAA+AWZEAAALNKiELX48O/7FgvHEggIQgAAsIjh45wQI8jmhFCOAQAAfkEmBAAAizAx1RyCEAAALNJihKjF8GFOSJBt2045BgAA+AWZEAAALOKWTW4f/n3vVnClQghCAACwCHNCzCEIAQDAIr7PCQmuTAhzQgAAgF+QCQEAwCLn5oT48AV2lGMAAEBnuH3ctj3YJqZSjgEAAH5BEAIAgEVaJ6b6cpixa9cu3XXXXUpMTJTNZtOWLVsuec3OnTt16623KiwsTNdee62Kioq8zg8aNEg2m63NkZOT4+kzbty4Nufnzp1rauwSQQgAAJZxK8Tnw4z6+nqlpqaqsLCwQ/2rqqo0efJkjR8/XpWVlVqwYIEefvhhvf32254+7733nk6ePOk5SkpKJEn33nuv171mz57t1W/58uWmxi4xJwQAgICVmZmpzMzMDvdfu3atkpOT9dRTT0mShg4dqt27d2vlypVyOBySpNjYWK9rfve73yklJUW33367V/uVV16p+Ph4n8ZPJgQAAIu0GDafD0lyuVxeR2NjoyXjKy8vV0ZGhlebw+FQeXl5u/2bmpq0fv16zZw5Uzab98qdDRs2qF+/frr55puVl5en7777zvR4yIQAAGCRFh9Xx7T8c3VMUlKSV/uSJUu0dOlSX4YmSXI6nYqLi/Nqi4uLk8vl0vfff6+IiAivc1u2bFFtba0eeughr/YHH3xQ11xzjRITE/Xhhx/qP/7jP3Tw4EG9/vrrpsZDEAIAQA9z7Ngx2e12z+uwsDC/jOPFF19UZmamEhMTvdrnzJnj+fMtt9yihIQETZgwQUeOHFFKSkqH708QAgCARdxGiNw+bNvu/ue27Xa73SsIsUp8fLxqamq82mpqamS329tkQY4ePart27d3KLuRlpYmSTp8+DBBCAAA/mBVOaarpKen66233vJqKykpUXp6epu+69atU//+/TV58uRL3reyslKSlJCQYGo8BCEAAFjELXkml3b2ejPOnDmjw4cPe15XVVWpsrJSMTExGjhwoPLy8nT8+HG9/PLLkqS5c+fq2Wef1aJFizRz5kzt2LFDr732mrZt2+Y9Drdb69atU3Z2tnr39g4Vjhw5oo0bN2rSpEnq27evPvzwQy1cuFBjx47VsGHDTI2fIAQAgAC1f/9+jR8/3vM6NzdXkpSdna2ioiKdPHlS1dXVnvPJycnatm2bFi5cqNWrV2vAgAF64YUXPMtzW23fvl3V1dWaOXNmm/cMDQ3V9u3btWrVKtXX1yspKUlZWVnKz883PX6bYQTZ9wYDAGAxl8ulqKgorXl/lCIiO//v++/PnNUjt76nurq6LpkT0tOQCQEAwCKd2Xr9x9cHk+D6tAAAoMcgEwIAgEXcssktXyamdv7aQEQQAgCARSjHmBNcnxYAAPQYZEIAALCI75uVBVdugCAEAACLuA2b3L5sVubDtYEouEIuAADQY5AJAQDAIm4fyzHuIMsNEIQAAGAR379FlyAEAAB0QotsavFhrw9frg1EwRVyAQCAHoNMCAAAFqEcYw5BCAAAFmmRbyWVFuuGEhCCK+QCAAA9BpkQAAAsQjnGHIIQAAAswhfYmRNcnxYAAPQYZEIAALCIIZvcPkxMNYJsnxCCEAAALEI5xpzg+rQAAKDHIBMCAIBF3IZNbqPzJRVfrg1EBCEAAFikxcdv0fXl2kBEEAIAgEXIhJgTXCEXAADoMciEAABgEbdC5Pbh3/e+XBuICEIAALBIi2FTiw8lFV+uDUTBFXIBAIAeg0wIAAAWYWKqOQQhAABYxPDxW3QNdkwFAADoemRCAACwSItsavHhS+h8uTYQEYQAAGARt+HbvA63YeFgAgDlGAAA4BdkQgAAsIjbx4mpvlwbiILr0wIA0IXcsvl8mLFr1y7dddddSkxMlM1m05YtWy55zc6dO3XrrbcqLCxM1157rYqKirzOL126VDabzesYMmSIV5+Ghgbl5OSob9++ioyMVFZWlmpqakyNXSIIAQDAMq07pvpymFFfX6/U1FQVFhZ2qH9VVZUmT56s8ePHq7KyUgsWLNDDDz+st99+26vfTTfdpJMnT3qO3bt3e51fuHCh3nzzTW3evFllZWU6ceKE7rnnHlNjlyjHAAAQsDIzM5WZmdnh/mvXrlVycrKeeuopSdLQoUO1e/durVy5Ug6Hw9Ovd+/eio+Pb/cedXV1evHFF7Vx40bdcccdkqR169Zp6NCh2rNnj2677bYOj4dMCAAAFmmdE+LLIUkul8vraGxstGR85eXlysjI8GpzOBwqLy/3ajt06JASExM1ePBgTZs2TdXV1Z5zFRUVam5u9rrPkCFDNHDgwDb3uRSCEAAALOKWzbN1e6eOf84JSUpKUlRUlOcoKCiwZHxOp1NxcXFebXFxcXK5XPr+++8lSWlpaSoqKlJxcbHWrFmjqqoq/fznP9fp06c99wgNDVV0dHSb+zidTlPjoRwDAEAPc+zYMdntds/rsLCwbnvv88s7w4YNU1pamq655hq99tprmjVrlqXvRRACAIBFjE6scPnx9ZJkt9u9ghCrxMfHt1nFUlNTI7vdroiIiHaviY6O1vXXX6/Dhw977tHU1KTa2lqvbEhNTc0F55FcCOUYAAAs4lMpxsdv4O2I9PR0lZaWerWVlJQoPT39gtecOXNGR44cUUJCgiRpxIgRuuKKK7zuc/DgQVVXV1/0Pu0hEwIAQIA6c+aMJ0MhnVuCW1lZqZiYGA0cOFB5eXk6fvy4Xn75ZUnS3Llz9eyzz2rRokWaOXOmduzYoddee03btm3z3OOxxx7TXXfdpWuuuUYnTpzQkiVL1KtXLz3wwAOSpKioKM2aNUu5ubmKiYmR3W7X/PnzlZ6ebmpljEQQAgCAZbp7x9T9+/dr/Pjxnte5ubmSpOzsbBUVFenkyZNeK1uSk5O1bds2LVy4UKtXr9aAAQP0wgsveC3P/fLLL/XAAw/om2++UWxsrMaMGaM9e/YoNjbW02flypUKCQlRVlaWGhsb5XA49Nxzz5n+vDbDMILs63IAALCWy+VSVFSU7v7/ZuqKq0I7fZ/m+ib99c6XVFdX1yVzQnoa5oQAAAC/oBwDAIBFOvP9Lz++PpgEZBDidrt14sQJ9enTRzZbcP0HAwCYYxiGTp8+rcTERIWEdG0BwNcVLl29OqanCcgg5MSJE0pKSvL3MAAAAeTYsWMaMGBAl74HQYg5ARmE9OnTR5I0YEm+QsLD/TwaAEBP8dH/md+mzeVyKSkpyfO7Az1HQAYhrSWYkPBwghAAgMfFVpR0R/meTIg5ARmEAADQExGEmMMSXQAA4BdkQgAAsIgh35bZBtvuoQQhAABYhHKMOZRjAACAX5AJAQDAImRCzCEIAQDAIgQh5lCOAQAAfkEmBAAAi5AJMYcgBAAAixiGTYYPgYQv1wYighAAACzils2nfUJ8uTYQMScEAAD4BZkQAAAswpwQcwhCAACwCHNCzKEcAwAA/IJMCAAAFqEcYw5BCAAAFqEcYw7lGAAA4BdkQgAAsIjhYzkm2DIhBCEAAFjEkGQYvl0fTCjHAAAAvyATAgCARdyyyca27R1GEAIAgEVYHWMOQQgAABZxGzbZ2Cekw5gTAgAA/IJMCAAAFjEMH1fHBNnyGIIQAAAswpwQcyjHAAAAvyATAgCARciEmEMQAgCARVgdYw7lGAAAAtSuXbt01113KTExUTabTVu2bLnkNTt37tStt96qsLAwXXvttSoqKvI6X1BQoFGjRqlPnz7q37+/pkyZooMHD3r1GTdunGw2m9cxd+5c0+MnEwIACAhVCx719xAuqbtXx9TX1ys1NVUzZ87UPffcc8n+VVVVmjx5subOnasNGzaotLRUDz/8sBISEuRwOCRJZWVlysnJ0ahRo3T27Fn9+te/1p133qlPP/1UV111ledes2fP1rJlyzyvr7zySnODF0EIAKAHCYRA42LOBSG+zAkx1z8zM1OZmZkd7r927VolJyfrqaeekiQNHTpUu3fv1sqVKz1BSHFxsdc1RUVF6t+/vyoqKjR27FhP+5VXXqn4+HhzA/4RyjEAAL+rWvBowAcg0g8TU305JMnlcnkdjY2NloyvvLxcGRkZXm0Oh0Pl5eUXvKaurk6SFBMT49W+YcMG9evXTzfffLPy8vL03XffmR6P6SDkUvWnhx56qE2daOLEiV59vv32W02bNk12u13R0dGaNWuWzpw5Y3rwAIDA0xpwnH/AW1JSkqKiojxHQUGBJfd1Op2Ki4vzaouLi5PL5dL333/fpr/b7daCBQv0s5/9TDfffLOn/cEHH9T69ev1zjvvKC8vT6+88op++ctfmh6P6XJMR+pPEydO1Lp16zyvw8LCvM5PmzZNJ0+eVElJiZqbmzVjxgzNmTNHGzduNDscAEAAudwDDuOfhy/XS9KxY8dkt9s97T/+PdpdcnJy9PHHH2v37t1e7XPmzPH8+ZZbblFCQoImTJigI0eOKCUlpcP3Nx2EdKT+FBYWdsE60Weffabi4mK99957GjlypCTpmWee0aRJk/Rf//VfSkxMNDskAAB6BKv2CbHb7V5BiFXi4+NVU1Pj1VZTUyO73a6IiAiv9nnz5mnr1q3atWuXBgwYcNH7pqWlSZIOHz7ctUFIR+zcuVP9+/fXT37yE91xxx168skn1bdvX0nn6lHR0dGeAESSMjIyFBISor1792rq1Klt7tfY2OhVD3O5XF0xbABAF7jcsx+BJD09XW+99ZZXW0lJidLT0z2vDcPQ/Pnz9cYbb2jnzp1KTk6+5H0rKyslSQkJCabGY/nE1IkTJ+rll19WaWmpfv/736usrEyZmZlqaWmRdK4e1b9/f69revfurZiYGDmdznbvWVBQ4FUbS0pKsnrYAIAuEHQBiGHBYcKZM2dUWVnpCQKqqqpUWVmp6upqSVJeXp6mT5/u6T937lx9/vnnWrRokQ4cOKDnnntOr732mhYuXOjpk5OTo/Xr12vjxo3q06ePnE6nnE6nZ87IkSNH9J//+Z+qqKjQF198ob/97W+aPn26xo4dq2HDhpkav+WZkPvvv9/z51tuuUXDhg1TSkqKdu7cqQkTJnTqnnl5ecrNzfW8drlcBCIA0IMFXfDRysdyjExeu3//fo0fP97zuvV3ZXZ2toqKinTy5ElPQCJJycnJ2rZtmxYuXKjVq1drwIABeuGFFzzLcyVpzZo1ks5tSHa+devW6aGHHlJoaKi2b9+uVatWqb6+XklJScrKylJ+fr7ZT9v1+4QMHjxY/fr10+HDhzVhwgTFx8fr1KlTXn3Onj2rb7/99oLzSMLCwvw2KQcA0HFBG3z4ybhx42RcZHORH++G2nrNBx98cMFrLnY/6dzKnbKysg6P8WK6fJ+QL7/8Ut98842nTpSenq7a2lpVVFR4+uzYsUNut9szsQUAEHgIQH7YMdWXI5iYzoScOXNGhw8f9rxurT/FxMQoJiZGTzzxhLKyshQfH68jR45o0aJFuvbaaz2pnqFDh2rixImaPXu21q5dq+bmZs2bN0/3338/K2MAIEARgJzDt+iaYzoTsn//fv30pz/VT3/6U0nn6k8//elPtXjxYvXq1Usffvih/vVf/1XXX3+9Zs2apREjRugf//iHVzllw4YNGjJkiCZMmKBJkyZpzJgx+uMf/2jdpwIAdBsCEHSW6UzIpepPb7/99iXvERMTw8ZkAIDLj2EzPbm0zfVBhC+wAwD4JHnVU16vgzkz0t3fohvoCEIAAJZqDUqCMhixat/2IMG36AIAusSPMyTAj5EJAQB0SHuZjYsFGsGYCWF1jDkEIQAAywVjAOIRZCUVXxCEAAA6JHnVU22Ci6AONuAz5oQAADqMeR4X11qO8eUIJmRCAAAdRubjElgdYwpBCADgkgg+0BUIQgAAsIztn4cv1wcPghAAAKxCOcYUghAA6AE6U+5gkigCHUEIAHQjK+dW/PheBCU9AJkQUwhCAKCLddekzou9DwFKN+FbdE0hCAGALnA5rSa5nD5LV+NbdM0hCAGAS+CXMNA1CEIAQAQasAhzQkwhCAFgOTO/0Nv7PhKr/HgeBIEGuhxzQkwhCAHgM19+uXdlYEDQ8YOqBY8yORU9DkEIAFP4xR64CES6ns04d/hyfTAhCAFwQQQcgEnMCTGFIARAGwQfaMXPAroSQQgAftEEETMlGX4uOoGJqaYQhABBil8wQBegHGNKiL8HAKD7EYAEt47+92cSK7oamRAgSBB44HytPw+XCjS6ch+XyxKZEFMIQoDLSHvfqsovEFxMR4KR9s7xc3UBBCGmEIQAAcbMX/78okBHtRfAXkxXlWoC/meWiammEIQAPVjA/4WMgNXRcg3gC4IQoIch8EBP0t7P4/mBiZXByuXws8+OqeaYXh2za9cu3XXXXUpMTJTNZtOWLVu8zhuGocWLFyshIUERERHKyMjQoUOHvPp8++23mjZtmux2u6KjozVr1iydOXPGpw8CBLqqBY9eFn8J4/LX+rPKz2s7DAuOIGI6CKmvr1dqaqoKCwvbPb98+XI9/fTTWrt2rfbu3aurrrpKDodDDQ0Nnj7Tpk3TJ598opKSEm3dulW7du3SnDlzOv8pgADHX+YIdvw/0DmXSgy0Z+fOnbr11lsVFhama6+9VkVFRW36FBYWatCgQQoPD1daWpr27dvndb6hoUE5OTnq27evIiMjlZWVpZqaGtPjNx2EZGZm6sknn9TUqVPbnDMMQ6tWrVJ+fr7uvvtuDRs2TC+//LJOnDjheTCfffaZiouL9cILLygtLU1jxozRM888o02bNunEiROmPwAQ6PjLF0BnXSox8GNVVVWaPHmyxo8fr8rKSi1YsEAPP/yw3n77bU+fV199Vbm5uVqyZInef/99paamyuFw6NSpU54+Cxcu1JtvvqnNmzerrKxMJ06c0D333GN6/JbOCamqqpLT6VRGRoanLSoqSmlpaSovL9f999+v8vJyRUdHa+TIkZ4+GRkZCgkJ0d69e9sNbhobG9XY2Oh57XK5rBw24BcEH7hcMHn1Bzb5OCfEZP/MzExlZmZ2uP/atWuVnJysp546999s6NCh2r17t1auXCmHwyFJWrFihWbPnq0ZM2Z4rtm2bZteeuklPf7446qrq9OLL76ojRs36o477pAkrVu3TkOHDtWePXt02223dXg8lu6Y6nQ6JUlxcXFe7XFxcZ5zTqdT/fv39zrfu3dvxcTEePr8WEFBgaKiojxHUlKSlcMGuh0BCICLcblcXsf5/xD3RXl5uVeiQJIcDofKy8slSU1NTaqoqPDqExISooyMDE+fiooKNTc3e/UZMmSIBg4c6OnTUQGxbXteXp7q6uo8x7Fjx/w9JKBTmMyHyxE/1+dp3SfEl0NSUlKS1z++CwoKLBme0+lsN1Hgcrn0/fff6+uvv1ZLS8slkwmhoaGKjo6+YJ+OsrQcEx8fL0mqqalRQkKCp72mpkbDhw/39Dm/riRJZ8+e1bfffuu5/sfCwsIUFhZm5VCBbsNfzggWl1rOa+a6gGXRjqnHjh2T3W73NF+uvwMtDUKSk5MVHx+v0tJST9Dhcrm0d+9ePfLII5Kk9PR01dbWqqKiQiNGjJAk7dixQ263W2lpaVYOB/Cry+ovVqCT+P+gc+x2u1cQYpX4+Pg2q1hqampkt9sVERGhXr16qVevXu32aU0UxMfHq6mpSbW1tV7ZkPP7dJTpcsyZM2dUWVmpyspKSecmo1ZWVqq6ulo2m00LFizQk08+qb/97W/66KOPNH36dCUmJmrKlCmSzk2CmThxombPnq19+/bpf//3fzVv3jzdf//9SkxMNDscoMchNQ30HN0+abaH7xOSnp6u0tJSr7aSkhKlp6dLkkJDQzVixAivPm63W6WlpZ4+I0aM0BVXXOHV5+DBg6qurvb06SjTmZD9+/dr/Pjxnte5ubmSpOzsbBUVFWnRokWqr6/XnDlzVFtbqzFjxqi4uFjh4eGeazZs2KB58+ZpwoQJCgkJUVZWlp5++mmzQwEA4KKqFjzarSsqu3vH1DNnzujw4cOe162JgZiYGA0cOFB5eXk6fvy4Xn75ZUnS3Llz9eyzz2rRokWaOXOmduzYoddee03btm3z3CM3N1fZ2dkaOXKkRo8erVWrVqm+vt6zWiYqKkqzZs1Sbm6uYmJiZLfbNX/+fKWnp5taGSN1IggZN26cDOPCT8lms2nZsmVatmzZBfvExMRo48aNZt8a6PHIgABBrpu/RfdSiYGTJ0+qurracz45OVnbtm3TwoULtXr1ag0YMEAvvPCCZ3muJN1333366quvtHjxYjmdTg0fPlzFxcVek1VXrlzpSSI0NjbK4XDoueeeM/1xbcbFIooeyuVyKSoqSgMLnlTIeRkWwJ8IQICeqfV3Rl1dXZfMszj/PQY9+f/49HvJ3dCgL/J/06Vj7Un4AjsAAKzSzZmQQEcQAviIDAiAVnyLrjkBsVkZ0FMRgABA55EJAQDAKuftetrp64MIQQgAAFZhTogplGMAAIBfkAkBAMAiTEw1hyAEAACrUI4xhXIM0EmsjAEA35AJAUwi+ABwQT6WY4ItE0IQAgCAVSjHmEIQAphAFgTARRGEmMKcEAAA4BdkQoALIOsBwCyW6JpDEAKIgAMA/IFyDIIeAQgA+AeZEAQ1AhAAlmJiqikEIQg6BB4AugpzQswhCEFQIPAAgJ6HIASXPQIQAN0qyLIZviAIwWWNAARAt2JOiCkEIbgsEXwAQM9HEILLBoEHAH9jYqo5BCG4LBCAAOgRKMeYQhCCgEbwAaAnIRNiDjumImARgABAYCMTgoBD8AGgx6IcYwpBCC75Sz151VPdNJILI/AAEBAIQkyhHINL8mcAULXgUQIQALhMkQlBj0TgASAQMTHVHMuDkKVLl+qJJ57warvhhht04MABSVJDQ4MeffRRbdq0SY2NjXI4HHruuecUFxdn9VDQQxFgALhsUY4xpUvKMTfddJNOnjzpOXbv3u05t3DhQr355pvavHmzysrKdOLECd1zzz1dMQxYiMABAGC1LinH9O7dW/Hx8W3a6+rq9OKLL2rjxo264447JEnr1q3T0KFDtWfPHt12223t3q+xsVGNjY2e1y6XqyuGjUuoWvCoT5NUCWQAXPbIhJjSJUHIoUOHlJiYqPDwcKWnp6ugoEADBw5URUWFmpublZGR4ek7ZMgQDRw4UOXl5RcMQgoKCtqUeOAf5wcSHQ1ICD4ABAvmhJhjeTkmLS1NRUVFKi4u1po1a1RVVaWf//znOn36tJxOp0JDQxUdHe11TVxcnJxO5wXvmZeXp7q6Os9x7Ngxq4cdtHwJEDqycoUABABwIZYHIZmZmbr33ns1bNgwORwOvfXWW6qtrdVrr73W6XuGhYXJbrd7Heg5zg9GWv/M0loAQcmw4OiEwsJCDRo0SOHh4UpLS9O+ffsu2Le5uVnLli1TSkqKwsPDlZqaquLiYq8+gwYNks1ma3Pk5OR4+owbN67N+blz55oad5fvExIdHa3rr79ehw8fVnx8vJqamlRbW+vVp6ampt05JOhaVgcJBB0Agl1rOcaXw6xXX31Vubm5WrJkid5//32lpqbK4XDo1KlT7fbPz8/X888/r2eeeUaffvqp5s6dq6lTp+qDDz7w9Hnvvfe8FpiUlJRIku69916ve82ePdur3/Lly02NvcuDkDNnzujIkSNKSEjQiBEjdMUVV6i0tNRz/uDBg6qurlZ6enpXDwUAgK7lh0zIihUrNHv2bM2YMUM33nij1q5dqyuvvFIvvfRSu/1feeUV/frXv9akSZM0ePBgPfLII5o0aZKeeuqHeX6xsbGKj4/3HFu3blVKSopuv/12r3tdeeWVXv3MViosD0Iee+wxlZWV6YsvvtC7776rqVOnqlevXnrggQcUFRWlWbNmKTc3V++8844qKio0Y8YMpaenX3BSKgAAwcblcnkd568QPV9TU5MqKiq8FnyEhIQoIyND5eXl7V7T2Nio8PBwr7aIiAiv7TR+/B7r16/XzJkzZbPZvM5t2LBB/fr1080336y8vDx99913Zj6m9atjvvzySz3wwAP65ptvFBsbqzFjxmjPnj2KjY2VJK1cuVIhISHKysry2qwM3YvSCQB0AYuW6CYlJXk1L1myREuXLm3T/euvv1ZLS0ubDT/j4uI8m4T+mMPh0IoVKzR27FilpKSotLRUr7/+ulpaWtrtv2XLFtXW1uqhhx7yan/wwQd1zTXXKDExUR9++KH+4z/+QwcPHtTrr7/esc+qLghCNm3adNHz4eHhKiwsVGFhodVvDQCAX9n+efhyvSQdO3bMq7QRFhbmy7C8rF69WrNnz9aQIUNks9mUkpKiGTNmXLB88+KLLyozM1OJiYle7XPmzPH8+ZZbblFCQoImTJigI0eOKCUlpUNj4QvsghBZEADo2X68IvRCQUi/fv3Uq1cv1dTUeLVfbMFHbGystmzZovr6eh09elQHDhxQZGSkBg8e3Kbv0aNHtX37dj388MOXHHNaWpok6fDhw5fs24ogJMgQgABAF+rmiamhoaEaMWKE14IPt9ut0tLSSy74CA8P19VXX62zZ8/qL3/5i+6+++42fdatW6f+/ftr8uTJlxxLZWWlJCkhIaHD4+dbdAEAsIg/dkzNzc1Vdna2Ro4cqdGjR2vVqlWqr6/XjBkzJEnTp0/X1VdfrYKCAknS3r17dfz4cQ0fPlzHjx/X0qVL5Xa7tWjRIq/7ut1urVu3TtnZ2erd2ztcOHLkiDZu3KhJkyapb9+++vDDD7Vw4UKNHTtWw4YN6/DYCUIAAAhg9913n7766istXrxYTqdTw4cPV3FxsWeyanV1tUJCfih8NDQ0KD8/X59//rkiIyM1adIkvfLKK212M9++fbuqq6s1c+bMNu8ZGhqq7du3ewKepKQkZWVlKT8/39TYbYZhBNxO9S6XS1FRURpY8KRCfrTMCBdHOQZAsGn9nVFXV9dlO263vsdN//f/q15hnf+91NLYoE+e/3WXjrUnIRMSRAhAAKAbBNw/7f2HialBggAEANDTkAkBAMAi/piYGsgIQoIAWRAA6CYW7ZgaLAhCLnMEIADQfciEmMOcEAAA4BdkQgAAsArlGFMIQgAAsAjlGHMoxwAAAL8gEwIAgFUox5hCEHIZY2UMAHQzghBTKMcAAAC/IBMCAIBFmJhqDkEIAABWoRxjCuUYAADgF2RCLlNMSgWA7mczDNmMzqczfLk2EBGEAABgFcoxphCEAABgESammsOcEAAA4BdkQi5DzAcBAD+hHGMKQQgAABahHGMO5RgAAOAXZEIAALAK5RhTCEIuM8wHAQD/oRxjDuUYAADgF34NQgoLCzVo0CCFh4crLS1N+/bt8+dwAADwjWHBEUT8FoS8+uqrys3N1ZIlS/T+++8rNTVVDodDp06d8teQAADwWWtJpjNHsPFbELJixQrNnj1bM2bM0I033qi1a9fqyiuv1EsvveSvIQEAgG7kl4mpTU1NqqioUF5enqctJCREGRkZKi8vb9O/sbFRjY2Nntd1dXWSJHdDQ9cPNoB89H/my+Vy+XsYANCjtP69aHTHl8MZxrnDl+uDiF+CkK+//lotLS2Ki4vzao+Li9OBAwfa9C8oKNATTzzRpv3LJ57ssjEGoqi8fH8PAQB6rNOnTysqKqpL34PVMeYExBLdvLw85ebmel673W4dPXpUw4cP17Fjx2S32/04usDmcrmUlJTEc/QRz9EaPEfr8Cx/YBiGTp8+rcTExG54M7FPiAl+CUL69eunXr16qaamxqu9pqZG8fHxbfqHhYUpLCzMqy0k5Nx0FrvdHvT/g1mB52gNnqM1eI7W4Vme09UZEHSOXyamhoaGasSIESotLfW0ud1ulZaWKj093R9DAgDAZza370cw8Vs5Jjc3V9nZ2Ro5cqRGjx6tVatWqb6+XjNmzPDXkAAA8A3lGFP8FoTcd999+uqrr7R48WI5nU4NHz5cxcXFbSarXkhYWJiWLFnSpkwDc3iO1uA5WoPnaB2eJQKBzeiWNUsAAFy+XC6XoqKiNPruJ9X7ivBO3+dsc4P2/TVfdXV1pubyFBYW6g9/+IOcTqdSU1P1zDPPaPTo0e32bW5uVkFBgf70pz/p+PHjuuGGG/T73/9eEydO9PRZunRpm1WpN9xwg9cK1oaGBj366KPatGmTGhsb5XA49Nxzz3U4mSDx3TEAAFindZ8QXw6TzO5Anp+fr+eff17PPPOMPv30U82dO1dTp07VBx984NXvpptu0smTJz3H7t27vc4vXLhQb775pjZv3qyysjKdOHFC99xzj6mxkwkBAMBHnkzIv/6n75mQv/3WVCYkLS1No0aN0rPPPivp3EKPpKQkzZ8/X48//nib/omJifrNb36jnJwcT1tWVpYiIiK0fv16SecyIVu2bFFlZWW771lXV6fY2Fht3LhRv/jFLyRJBw4c0NChQ1VeXq7bbrutQ2MnEwIAgEV8+d6Y8zc6c7lcXsf5u4afr3UH8oyMDE/bxXYgl87tQh4e7h0oRUREtMl0HDp0SImJiRo8eLCmTZum6upqz7mKigo1Nzd7ve+QIUM0cODAC75vewhCAACwikXfopuUlKSoqCjPUVBQ0O7bXWwHcqfT2e41DodDK1as0KFDh+R2u1VSUqLXX39dJ0+e9PRJS0tTUVGRiouLtWbNGlVVVennP/+5Tp8+LUlyOp0KDQ1VdHR0h9+3PQEZhBQWFmrQoEEKDw9XWlqa9u3b5+8h9Si7du3SXXfdpcTERNlsNm3ZssXrvGEYWrx4sRISEhQREaGMjAwdOnTIq8+3336radOmyW63Kzo6WrNmzdKZM2e68VP4X0FBgUaNGqU+ffqof//+mjJlig4ePOjVp6GhQTk5Oerbt68iIyOVlZXVZhO+6upqTZ48WVdeeaX69++vf//3f9fZs2e786P41Zo1azRs2DDPplnp6en6+9//7jnPM+yc3/3ud7LZbFqwYIGnjWd5+Th27Jjq6uo8x/nftear1atX67rrrtOQIUMUGhqqefPmacaMGZ5NQCUpMzNT9957r4YNGyaHw6G33npLtbW1eu211ywbhxSAQYjZCTjBqL6+XqmpqSosLGz3/PLly/X0009r7dq12rt3r6666io5HA41nPeFgNOmTdMnn3yikpISbd26Vbt27dKcOXO66yP0CGVlZcrJydGePXtUUlKi5uZm3Xnnnaqvr/f0udTErJaWFk2ePFlNTU1699139ac//UlFRUVavHixPz6SXwwYMEC/+93vVFFRof379+uOO+7Q3XffrU8++UQSz7Az3nvvPT3//PMaNmyYVzvP0v+sKse0Bu2tx4WWWpvdgVySYmNjtWXLFtXX1+vo0aM6cOCAIiMjNXjw4At+rujoaF1//fU6fPiwJCk+Pl5NTU2qra3t8Pu2ywgwo0ePNnJycjyvW1pajMTERKOgoMCPo+q5JBlvvPGG57Xb7Tbi4+ONP/zhD5622tpaIywszPif//kfwzAM49NPPzUkGe+9956nz9///nfDZrMZx48f77ax9zSnTp0yJBllZWWGYZx7bldccYWxefNmT5/PPvvMkGSUl5cbhmEYb731lhESEmI4nU5PnzVr1hh2u91obGzs3g/Qg/zkJz8xXnjhBZ5hJ5w+fdq47rrrjJKSEuP22283fvWrXxmGwc+jv9XV1RmSjNsmLTPG3L2808dtk5YZkoy6uroOv/fo0aONefPmeV63tLQYV199dYd/LzY1NRkpKSlGXl7eBfucPn3a+MlPfmKsXr3aMIwfft7+/Oc/e/ocOHDA6+etIwIqE9KZCTjwVlVVJafT6fUMo6KilJaW5nmG5eXlio6O1siRIz19MjIyFBISor1793b7mHuKuro6SVJMTIykjk3MKi8v1y233OJVr3U4HHK5XJ5MQDBpaWnRpk2bVF9fr/T0dJ5hJ+Tk5Gjy5Mlez0zi57GnsCoTYkZubq7++7//W3/605/02Wef6ZFHHvHagXz69Ole5Zy9e/fq9ddf1+eff65//OMfmjhxotxutxYtWuTp89hjj6msrExffPGF3n33XU2dOlW9evXSAw88IOnc741Zs2YpNzdX77zzjioqKjRjxgylp6d3eGWMFCDfotvqYhNwzt9ABRfWOmHoYpOYnE6n+vfv73W+d+/eiomJMTXh6HLidru1YMEC/exnP9PNN98sqWMTs5xOZ7vPuvVcsPjoo4+Unp6uhoYGRUZG6o033tCNN96oyspKnqEJmzZt0vvvv6/33nuvzTl+HoPXpXYgr66u9prv0dDQoPz8fH3++eeKjIzUpEmT9Morr3j97Hz55Zd64IEH9M033yg2NlZjxozRnj17FBsb6+mzcuVKhYSEKCsry2uzMjMCKggB/CUnJ0cff/xxmyVs6JgbbrhBlZWVqqur05///GdlZ2errKzM38MKKMeOHdOvfvUrlZSUtFleiR7ET98dM2/ePM2bN6/dczt37vR6ffvtt+vTTz+96P02bdp0yfcMDw9XYWHhBecfdkRAlWM6MwEH3lqf08WeYXx8fJuJvmfPntW3334blM953rx52rp1q9555x0NGDDA096RiVnx8fHtPuvWc8EiNDRU1157rUaMGKGCggKlpqZq9erVPEMTKioqdOrUKd16663q3bu3evfurbKyMj399NPq3bu34uLieJY9gD/KMYEsoIKQ0NBQjRgxQqWlpZ42t9ut0tJSpaen+3FkgSM5OVnx8fFez9Dlcmnv3r2eZ5ienq7a2lpVVFR4+uzYsUNut1tpaWndPmZ/MQxD8+bN0xtvvKEdO3YoOTnZ6/yIESN0xRVXeD3LgwcPqrq62utZfvTRR15BXUlJiex2u2688cbu+SA9kNvtVmNjI8/QhAkTJuijjz5SZWWl5xg5cqSmTZvm+TPPEoEm4Moxubm5ys7O1siRIzV69GitWrXKawIOpDNnzniWUUnnJqNWVlYqJiZGAwcO1IIFC/Tkk0/quuuuU3Jysn77298qMTFRU6ZMkSQNHTpUEydO1OzZs7V27Vo1Nzdr3rx5uv/++5WYmOinT9X9cnJytHHjRv31r39Vnz59PDXzqKgoRUREeE3MiomJkd1u1/z5870mZt1555268cYb9W//9m9avny5nE6n8vPzlZOTEzTfbpqXl6fMzEwNHDhQp0+f1saNG7Vz5069/fbbPEMT+vTp45mP1Oqqq65S3759Pe08yx7AbZw7fLk+iARcEHKpCTiQ9u/fr/Hjx3te5+bmSpKys7NVVFSkRYsWqb6+XnPmzFFtba3GjBmj4uJirzrzhg0bNG/ePE2YMMEz8ejpp5/u9s/iT2vWrJEkjRs3zqt93bp1euihhyRdemJWr169tHXrVj3yyCNKT0/XVVddpezsbC1btqy7PobfnTp1StOnT9fJkycVFRWlYcOG6e2339a//Mu/SOIZWoln2QP4aU5IoOIL7AAA8FHrF9j9XxlP+PwFdu9uX2LqC+wCWcBlQgAA6Kls8m1yqc2ykQQGghAAAKxiGOcOX64PIgG1OgYAAFw+yIQAAGARX/f6CLZ9QghCAACwCqtjTCEIAQDAIjbDkM2HeR2+XBuImBMCAAD8gkwIAABWcf/z8OX6IEIQAgCARSjHmEM5BgAA+AWZEAAArMLqGFMIQgAAsAo7pppCOQYAAPgFmRAAACzCjqnmEIQAAGAVyjGmUI4BAAB+QSYEAACL2NznDl+uDyYEIQAAWIVyjCkEIQAAWIV9QkxhTggAAPALMiEAAFiE744xhyAEAACrMCfEFMoxAADAL8iEAABgFUOSL8tsgysRQhACAIBVmBNiDuUYAADgF2RCAACwiiEfJ6ZaNpKAQBACAIBVWB1jCuUYAADgF2RCAACwiluSzcfrgwiZEAAALNK6OsaXozMKCws1aNAghYeHKy0tTfv27btg3+bmZi1btkwpKSkKDw9XamqqiouLvfoUFBRo1KhR6tOnj/r3768pU6bo4MGDXn3GjRsnm83mdcydO9fUuAlCAACwSuucEF8Ok1599VXl5uZqyZIlev/995WamiqHw6FTp0612z8/P1/PP/+8nnnmGX366aeaO3eupk6dqg8++MDTp6ysTDk5OdqzZ49KSkrU3NysO++8U/X19V73mj17tk6ePOk5li9fbmrsNsMIslkwAABYzOVyKSoqShNu+nf17hXW6fucbWlU6Sd/UF1dnex2e4euSUtL06hRo/Tss89Kktxut5KSkjR//nw9/vjjbfonJibqN7/5jXJycjxtWVlZioiI0Pr169t9j6+++kr9+/dXWVmZxo4dK+lcJmT48OFatWqVyU/5AzIhAABYxaJMiMvl8joaGxvbfbumpiZVVFQoIyPD0xYSEqKMjAyVl5e3e01jY6PCw8O92iIiIrR79+4Lfqy6ujpJUkxMjFf7hg0b1K9fP918883Ky8vTd999d+lndB6CEAAArGJREJKUlKSoqCjPUVBQ0O7bff3112ppaVFcXJxXe1xcnJxOZ7vXOBwOrVixQocOHZLb7VZJSYlef/11nTx5st3+brdbCxYs0M9+9jPdfPPNnvYHH3xQ69ev1zvvvKO8vDy98sor+uUvf2nqcbE6BgCAHubYsWNe5ZiwsM6XeH5s9erVmj17toYMGSKbzaaUlBTNmDFDL730Urv9c3Jy9PHHH7fJlMyZM8fz51tuuUUJCQmaMGGCjhw5opSUlA6NhUwIAABWcVtwSLLb7V7HhYKQfv36qVevXqqpqfFqr6mpUXx8fLvXxMbGasuWLaqvr9fRo0d14MABRUZGavDgwW36zps3T1u3btU777yjAQMGXPSjp6WlSZIOHz580X7nIwgBAMAi3b1ENzQ0VCNGjFBpaamnze12q7S0VOnp6Re9Njw8XFdffbXOnj2rv/zlL7r77rs95wzD0Lx58/TGG29ox44dSk5OvuRYKisrJUkJCQkdHj/lGAAAAlhubq6ys7M1cuRIjR49WqtWrVJ9fb1mzJghSZo+fbquvvpqz7ySvXv36vjx4xo+fLiOHz+upUuXyu12a9GiRZ575uTkaOPGjfrrX/+qPn36eOaXREVFKSIiQkeOHNHGjRs1adIk9e3bVx9++KEWLlyosWPHatiwYR0eO0EIAABW8cN3x9x333366quvtHjxYjmdTg0fPlzFxcWeyarV1dUKCfmh8NHQ0KD8/Hx9/vnnioyM1KRJk/TKK68oOjra02fNmjWSzi3DPd+6dev00EMPKTQ0VNu3b/cEPElJScrKylJ+fr6psbNPCAAAPmrdJyQjZYHP+4RsP7LK1D4hgYw5IQAAwC8oxwAAYBU/lGMCGUEIAACW8TEIEUEIAADoDDIhpjAnBAAA+AWZEAAArOI25FNJxR1cmRCCEAAArGK4zx2+XB9EKMcAAAC/IBMCAIBVmJhqCkEIAABWYU6IKZRjAACAX5AJAQDAKpRjTCEIAQDAKoZ8DEIsG0lAoBwDAAD8gkwIAABWoRxjCkEIAABWcbsl+bDhmDu4NisjCAEAwCpkQkxhTggAAPALMiEAAFiFTIgpBCEAAFiFHVNNoRwDAAD8gkwIAAAWMQy3DKPzK1x8uTYQEYQAAGAVw/CtpBJkc0IoxwAAAL8gEwIAgFUMHyemBlkmhCAEAACruN2SzYd5HUE2J4RyDAAA8AsyIQAAWIVyjCkEIQAAWMRwu2X4UI5hiS4AAOgcMiGmMCcEAAD4BZkQAACs4jYkG5mQjiIIAQDAKoYhyZclusEVhFCOAQAAfkEmBAAAixhuQ4YP5RgjyDIhBCEAAFjFcMu3ckxwLdGlHAMAQIArLCzUoEGDFB4errS0NO3bt++CfZubm7Vs2TKlpKQoPDxcqampKi4uNn3PhoYG5eTkqG/fvoqMjFRWVpZqampMjZsgBAAAixhuw+fDrFdffVW5ublasmSJ3n//faWmpsrhcOjUqVPt9s/Pz9fzzz+vZ555Rp9++qnmzp2rqVOn6oMPPjB1z4ULF+rNN9/U5s2bVVZWphMnTuiee+4xNXabEWwFKAAALOZyuRQVFaUxmqTeuqLT9zmrZu3WWzp27JjsdrunPSwsTGFhYe1ek5aWplGjRunZZ5+VJLndbiUlJWn+/Pl6/PHH2/RPTEzUb37zG+Xk5HjasrKyFBERofXr13fonnV1dYqNjdXGjRv1i1/8QpJ04MABDR06VOXl5brttts69HmZEwIAgI9CQ0MVHx+v3c63fL5XZGSkkpKSvNqWLFmipUuXtunb1NSkiooK5eXledpCQkKUkZGh8vLydu/f2Nio8PBwr7aIiAjt3r27w/esqKhQc3OzMjIyPH2GDBmigQMHEoQAANCdwsPDVVVVpaamJp/vZRiGbDabV9uFsiBff/21WlpaFBcX59UeFxenAwcOtHuNw+HQihUrNHbsWKWkpKi0tFSvv/66WlpaOnxPp9Op0NBQRUdHt+njdDo7/FkJQgAAsEB4eHibDENPtHr1as2ePVtDhgyRzWZTSkqKZsyYoZdeeqnbx8LEVAAAAlS/fv3Uq1evNqtSampqFB8f3+41sbGx2rJli+rr63X06FEdOHBAkZGRGjx4cIfvGR8fr6amJtXW1nb4fdtDEAIAQIAKDQ3ViBEjVFpa6mlzu90qLS1Venr6Ra8NDw/X1VdfrbNnz+ovf/mL7r777g7fc8SIEbriiiu8+hw8eFDV1dWXfN/zUY4BACCA5ebmKjs7WyNHjtTo0aO1atUq1dfXa8aMGZKk6dOn6+qrr1ZBQYEkae/evTp+/LiGDx+u48ePa+nSpXK73Vq0aFGH7xkVFaVZs2YpNzdXMTExstvtmj9/vtLT0zs8KVUiCAEAIKDdd999+uqrr7R48WI5nU4NHz5cxcXFnoml1dXVCgn5ofDR0NCg/Px8ff7554qMjNSkSZP0yiuveE0yvdQ9JWnlypUKCQlRVlaWGhsb5XA49Nxzz5kaO/uEAAAAv2BOCAAA8AuCEAAA4BcEIQAAwC8IQgAAgF8QhAAAAL8gCAEAAH5BEAIAAPyCIAQAAPgFQQgAAPALghAAAOAXBCEAAMAv/n9bRTlQZLEqhwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code for masking the islands"
      ],
      "metadata": {
        "id": "znXSxUwQHmaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas\n",
        "from shapely.geometry import mapping"
      ],
      "metadata": {
        "id": "8bitkzqcFx2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_surf.rio.write_crs(\"epsg:4326\", inplace=True)\n",
        "islands_shape  = geopandas.read_file('/content/drive/MyDrive/4DVarNet/DFM_data/Wadden_Sea_Islands.shx', crs=\"epsg:4326\")\n",
        "data_isl_mask = data_surf.rio.clip(islands_shape.geometry.apply(mapping), islands_shape.crs, drop=False, invert=True)"
      ],
      "metadata": {
        "id": "K9bsJu2VF1Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_isl_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "qg7GteXcHDqi",
        "outputId": "bed0a00d-311b-4127-a543-3e297c2ee0f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<xarray.Dataset>\n",
              "Dimensions:                        (time: 732, y: 200, x: 482)\n",
              "Coordinates:\n",
              "  * time                           (time) datetime64[ns] 2016-01-01 ... 2018-...\n",
              "  * y                              (y) float64 52.55 52.56 52.57 ... 53.96 53.97\n",
              "  * x                              (x) float64 4.004 4.011 4.018 ... 7.424 7.431\n",
              "    spatial_ref                    int64 0\n",
              "Data variables:\n",
              "    __xarray_dataarray_variable__  (time, y, x) float64 13.12 13.84 ... nan nan\n",
              "    SPM                            (time, y, x) float64 1.118 1.141 ... nan nan"
            ],
            "text/html": [
              "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
              "<defs>\n",
              "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
              "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
              "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
              "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
              "</symbol>\n",
              "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
              "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
              "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "</symbol>\n",
              "</defs>\n",
              "</svg>\n",
              "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
              " *\n",
              " */\n",
              "\n",
              ":root {\n",
              "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
              "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
              "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
              "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
              "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
              "  --xr-background-color: var(--jp-layout-color0, white);\n",
              "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
              "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
              "}\n",
              "\n",
              "html[theme=dark],\n",
              "body[data-theme=dark],\n",
              "body.vscode-dark {\n",
              "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
              "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
              "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
              "  --xr-border-color: #1F1F1F;\n",
              "  --xr-disabled-color: #515151;\n",
              "  --xr-background-color: #111111;\n",
              "  --xr-background-color-row-even: #111111;\n",
              "  --xr-background-color-row-odd: #313131;\n",
              "}\n",
              "\n",
              ".xr-wrap {\n",
              "  display: block !important;\n",
              "  min-width: 300px;\n",
              "  max-width: 700px;\n",
              "}\n",
              "\n",
              ".xr-text-repr-fallback {\n",
              "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-header {\n",
              "  padding-top: 6px;\n",
              "  padding-bottom: 6px;\n",
              "  margin-bottom: 4px;\n",
              "  border-bottom: solid 1px var(--xr-border-color);\n",
              "}\n",
              "\n",
              ".xr-header > div,\n",
              ".xr-header > ul {\n",
              "  display: inline;\n",
              "  margin-top: 0;\n",
              "  margin-bottom: 0;\n",
              "}\n",
              "\n",
              ".xr-obj-type,\n",
              ".xr-array-name {\n",
              "  margin-left: 2px;\n",
              "  margin-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-obj-type {\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-sections {\n",
              "  padding-left: 0 !important;\n",
              "  display: grid;\n",
              "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
              "}\n",
              "\n",
              ".xr-section-item {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-section-item input {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-section-item input + label {\n",
              "  color: var(--xr-disabled-color);\n",
              "}\n",
              "\n",
              ".xr-section-item input:enabled + label {\n",
              "  cursor: pointer;\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-section-item input:enabled + label:hover {\n",
              "  color: var(--xr-font-color0);\n",
              "}\n",
              "\n",
              ".xr-section-summary {\n",
              "  grid-column: 1;\n",
              "  color: var(--xr-font-color2);\n",
              "  font-weight: 500;\n",
              "}\n",
              "\n",
              ".xr-section-summary > span {\n",
              "  display: inline-block;\n",
              "  padding-left: 0.5em;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:disabled + label {\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-section-summary-in + label:before {\n",
              "  display: inline-block;\n",
              "  content: '►';\n",
              "  font-size: 11px;\n",
              "  width: 15px;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:disabled + label:before {\n",
              "  color: var(--xr-disabled-color);\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked + label:before {\n",
              "  content: '▼';\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked + label > span {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-section-summary,\n",
              ".xr-section-inline-details {\n",
              "  padding-top: 4px;\n",
              "  padding-bottom: 4px;\n",
              "}\n",
              "\n",
              ".xr-section-inline-details {\n",
              "  grid-column: 2 / -1;\n",
              "}\n",
              "\n",
              ".xr-section-details {\n",
              "  display: none;\n",
              "  grid-column: 1 / -1;\n",
              "  margin-bottom: 5px;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked ~ .xr-section-details {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-array-wrap {\n",
              "  grid-column: 1 / -1;\n",
              "  display: grid;\n",
              "  grid-template-columns: 20px auto;\n",
              "}\n",
              "\n",
              ".xr-array-wrap > label {\n",
              "  grid-column: 1;\n",
              "  vertical-align: top;\n",
              "}\n",
              "\n",
              ".xr-preview {\n",
              "  color: var(--xr-font-color3);\n",
              "}\n",
              "\n",
              ".xr-array-preview,\n",
              ".xr-array-data {\n",
              "  padding: 0 5px !important;\n",
              "  grid-column: 2;\n",
              "}\n",
              "\n",
              ".xr-array-data,\n",
              ".xr-array-in:checked ~ .xr-array-preview {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-array-in:checked ~ .xr-array-data,\n",
              ".xr-array-preview {\n",
              "  display: inline-block;\n",
              "}\n",
              "\n",
              ".xr-dim-list {\n",
              "  display: inline-block !important;\n",
              "  list-style: none;\n",
              "  padding: 0 !important;\n",
              "  margin: 0;\n",
              "}\n",
              "\n",
              ".xr-dim-list li {\n",
              "  display: inline-block;\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "}\n",
              "\n",
              ".xr-dim-list:before {\n",
              "  content: '(';\n",
              "}\n",
              "\n",
              ".xr-dim-list:after {\n",
              "  content: ')';\n",
              "}\n",
              "\n",
              ".xr-dim-list li:not(:last-child):after {\n",
              "  content: ',';\n",
              "  padding-right: 5px;\n",
              "}\n",
              "\n",
              ".xr-has-index {\n",
              "  font-weight: bold;\n",
              "}\n",
              "\n",
              ".xr-var-list,\n",
              ".xr-var-item {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-var-item > div,\n",
              ".xr-var-item label,\n",
              ".xr-var-item > .xr-var-name span {\n",
              "  background-color: var(--xr-background-color-row-even);\n",
              "  margin-bottom: 0;\n",
              "}\n",
              "\n",
              ".xr-var-item > .xr-var-name:hover span {\n",
              "  padding-right: 5px;\n",
              "}\n",
              "\n",
              ".xr-var-list > li:nth-child(odd) > div,\n",
              ".xr-var-list > li:nth-child(odd) > label,\n",
              ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
              "  background-color: var(--xr-background-color-row-odd);\n",
              "}\n",
              "\n",
              ".xr-var-name {\n",
              "  grid-column: 1;\n",
              "}\n",
              "\n",
              ".xr-var-dims {\n",
              "  grid-column: 2;\n",
              "}\n",
              "\n",
              ".xr-var-dtype {\n",
              "  grid-column: 3;\n",
              "  text-align: right;\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-var-preview {\n",
              "  grid-column: 4;\n",
              "}\n",
              "\n",
              ".xr-index-preview {\n",
              "  grid-column: 2 / 5;\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-var-name,\n",
              ".xr-var-dims,\n",
              ".xr-var-dtype,\n",
              ".xr-preview,\n",
              ".xr-attrs dt {\n",
              "  white-space: nowrap;\n",
              "  overflow: hidden;\n",
              "  text-overflow: ellipsis;\n",
              "  padding-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-var-name:hover,\n",
              ".xr-var-dims:hover,\n",
              ".xr-var-dtype:hover,\n",
              ".xr-attrs dt:hover {\n",
              "  overflow: visible;\n",
              "  width: auto;\n",
              "  z-index: 1;\n",
              "}\n",
              "\n",
              ".xr-var-attrs,\n",
              ".xr-var-data,\n",
              ".xr-index-data {\n",
              "  display: none;\n",
              "  background-color: var(--xr-background-color) !important;\n",
              "  padding-bottom: 5px !important;\n",
              "}\n",
              "\n",
              ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
              ".xr-var-data-in:checked ~ .xr-var-data,\n",
              ".xr-index-data-in:checked ~ .xr-index-data {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              ".xr-var-data > table {\n",
              "  float: right;\n",
              "}\n",
              "\n",
              ".xr-var-name span,\n",
              ".xr-var-data,\n",
              ".xr-index-name div,\n",
              ".xr-index-data,\n",
              ".xr-attrs {\n",
              "  padding-left: 25px !important;\n",
              "}\n",
              "\n",
              ".xr-attrs,\n",
              ".xr-var-attrs,\n",
              ".xr-var-data,\n",
              ".xr-index-data {\n",
              "  grid-column: 1 / -1;\n",
              "}\n",
              "\n",
              "dl.xr-attrs {\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "  display: grid;\n",
              "  grid-template-columns: 125px auto;\n",
              "}\n",
              "\n",
              ".xr-attrs dt,\n",
              ".xr-attrs dd {\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "  float: left;\n",
              "  padding-right: 10px;\n",
              "  width: auto;\n",
              "}\n",
              "\n",
              ".xr-attrs dt {\n",
              "  font-weight: normal;\n",
              "  grid-column: 1;\n",
              "}\n",
              "\n",
              ".xr-attrs dt:hover span {\n",
              "  display: inline-block;\n",
              "  background: var(--xr-background-color);\n",
              "  padding-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-attrs dd {\n",
              "  grid-column: 2;\n",
              "  white-space: pre-wrap;\n",
              "  word-break: break-all;\n",
              "}\n",
              "\n",
              ".xr-icon-database,\n",
              ".xr-icon-file-text2,\n",
              ".xr-no-icon {\n",
              "  display: inline-block;\n",
              "  vertical-align: middle;\n",
              "  width: 1em;\n",
              "  height: 1.5em !important;\n",
              "  stroke-width: 0;\n",
              "  stroke: currentColor;\n",
              "  fill: currentColor;\n",
              "}\n",
              "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
              "Dimensions:                        (time: 732, y: 200, x: 482)\n",
              "Coordinates:\n",
              "  * time                           (time) datetime64[ns] 2016-01-01 ... 2018-...\n",
              "  * y                              (y) float64 52.55 52.56 52.57 ... 53.96 53.97\n",
              "  * x                              (x) float64 4.004 4.011 4.018 ... 7.424 7.431\n",
              "    spatial_ref                    int64 0\n",
              "Data variables:\n",
              "    __xarray_dataarray_variable__  (time, y, x) float64 13.12 13.84 ... nan nan\n",
              "    SPM                            (time, y, x) float64 1.118 1.141 ... nan nan</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-bc27b61b-1f50-46b6-bc72-b7283fc3b1bd' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-bc27b61b-1f50-46b6-bc72-b7283fc3b1bd' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 732</li><li><span class='xr-has-index'>y</span>: 200</li><li><span class='xr-has-index'>x</span>: 482</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-5b77b1fa-98d8-4e37-9c37-cd468794b68f' class='xr-section-summary-in' type='checkbox'  checked><label for='section-5b77b1fa-98d8-4e37-9c37-cd468794b68f' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2016-01-01 ... 2018-01-01</div><input id='attrs-61b1d7d4-e7d7-4764-b5b2-927c91beff3d' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-61b1d7d4-e7d7-4764-b5b2-927c91beff3d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3e1326c4-f7ac-4ecf-bf66-77c715db3877' class='xr-var-data-in' type='checkbox'><label for='data-3e1326c4-f7ac-4ecf-bf66-77c715db3877' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>time</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;2016-01-01T00:00:00.000000000&#x27;, &#x27;2016-01-02T00:00:00.000000000&#x27;,\n",
              "       &#x27;2016-01-03T00:00:00.000000000&#x27;, ..., &#x27;2017-12-30T00:00:00.000000000&#x27;,\n",
              "       &#x27;2017-12-31T00:00:00.000000000&#x27;, &#x27;2018-01-01T00:00:00.000000000&#x27;],\n",
              "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>y</span></div><div class='xr-var-dims'>(y)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>52.55 52.56 52.57 ... 53.96 53.97</div><input id='attrs-50001450-a260-4ea8-a031-3a0bed4d54ad' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-50001450-a260-4ea8-a031-3a0bed4d54ad' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a1919331-0962-412b-b192-2e16b85fd93a' class='xr-var-data-in' type='checkbox'><label for='data-a1919331-0962-412b-b192-2e16b85fd93a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>axis :</span></dt><dd>Y</dd><dt><span>long_name :</span></dt><dd>latitude</dd><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd></dl></div><div class='xr-var-data'><pre>array([52.553562, 52.560688, 52.567813, 52.574938, 52.582063, 52.589188,\n",
              "       52.596313, 52.603438, 52.610563, 52.617688, 52.624813, 52.631938,\n",
              "       52.639063, 52.646188, 52.653313, 52.660438, 52.667563, 52.674688,\n",
              "       52.681813, 52.688938, 52.696063, 52.703188, 52.710313, 52.717438,\n",
              "       52.724563, 52.731688, 52.738813, 52.745938, 52.753063, 52.760188,\n",
              "       52.767313, 52.774438, 52.781563, 52.788688, 52.795813, 52.802938,\n",
              "       52.810063, 52.817188, 52.824313, 52.831438, 52.838563, 52.845688,\n",
              "       52.852813, 52.859938, 52.867063, 52.874188, 52.881313, 52.888438,\n",
              "       52.895563, 52.902688, 52.909813, 52.916938, 52.924063, 52.931188,\n",
              "       52.938313, 52.945438, 52.952563, 52.959688, 52.966813, 52.973938,\n",
              "       52.981063, 52.988188, 52.995313, 53.002438, 53.009563, 53.016688,\n",
              "       53.023813, 53.030938, 53.038063, 53.045188, 53.052313, 53.059438,\n",
              "       53.066563, 53.073688, 53.080813, 53.087938, 53.095063, 53.102188,\n",
              "       53.109313, 53.116438, 53.123563, 53.130688, 53.137813, 53.144938,\n",
              "       53.152063, 53.159188, 53.166313, 53.173438, 53.180563, 53.187688,\n",
              "       53.194813, 53.201938, 53.209063, 53.216188, 53.223313, 53.230438,\n",
              "       53.237563, 53.244688, 53.251813, 53.258938, 53.266063, 53.273188,\n",
              "       53.280313, 53.287438, 53.294563, 53.301688, 53.308813, 53.315938,\n",
              "       53.323063, 53.330188, 53.337313, 53.344438, 53.351563, 53.358688,\n",
              "       53.365813, 53.372938, 53.380063, 53.387188, 53.394313, 53.401438,\n",
              "       53.408563, 53.415688, 53.422813, 53.429938, 53.437063, 53.444188,\n",
              "       53.451313, 53.458438, 53.465563, 53.472688, 53.479813, 53.486938,\n",
              "       53.494063, 53.501188, 53.508313, 53.515438, 53.522563, 53.529688,\n",
              "       53.536813, 53.543938, 53.551063, 53.558188, 53.565313, 53.572438,\n",
              "       53.579563, 53.586688, 53.593813, 53.600938, 53.608063, 53.615188,\n",
              "       53.622313, 53.629438, 53.636563, 53.643688, 53.650813, 53.657938,\n",
              "       53.665063, 53.672188, 53.679313, 53.686438, 53.693563, 53.700688,\n",
              "       53.707813, 53.714938, 53.722063, 53.729188, 53.736313, 53.743438,\n",
              "       53.750563, 53.757688, 53.764813, 53.771938, 53.779063, 53.786188,\n",
              "       53.793313, 53.800438, 53.807563, 53.814688, 53.821813, 53.828938,\n",
              "       53.836063, 53.843188, 53.850313, 53.857438, 53.864563, 53.871688,\n",
              "       53.878813, 53.885938, 53.893063, 53.900188, 53.907313, 53.914438,\n",
              "       53.921563, 53.928688, 53.935813, 53.942938, 53.950063, 53.957188,\n",
              "       53.964313, 53.971438])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>x</span></div><div class='xr-var-dims'>(x)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>4.004 4.011 4.018 ... 7.424 7.431</div><input id='attrs-c60f676d-a6b7-491e-b5a6-91a3346d30e2' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-c60f676d-a6b7-491e-b5a6-91a3346d30e2' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e6346f0e-f090-48be-b1ca-bffa50a05d02' class='xr-var-data-in' type='checkbox'><label for='data-e6346f0e-f090-48be-b1ca-bffa50a05d02' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>axis :</span></dt><dd>X</dd><dt><span>long_name :</span></dt><dd>longitude</dd><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd></dl></div><div class='xr-var-data'><pre>array([4.003563, 4.010688, 4.017813, ..., 7.416438, 7.423563, 7.430688])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>spatial_ref</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0</div><input id='attrs-d8d59cf6-6eba-4424-a3b8-9a6ef3ea129a' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-d8d59cf6-6eba-4424-a3b8-9a6ef3ea129a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b76c9800-6690-4b15-a23a-14ef3261fd33' class='xr-var-data-in' type='checkbox'><label for='data-b76c9800-6690-4b15-a23a-14ef3261fd33' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>crs_wkt :</span></dt><dd>GEOGCS[&quot;WGS 84&quot;,DATUM[&quot;WGS_1984&quot;,SPHEROID[&quot;WGS 84&quot;,6378137,298.257223563,AUTHORITY[&quot;EPSG&quot;,&quot;7030&quot;]],AUTHORITY[&quot;EPSG&quot;,&quot;6326&quot;]],PRIMEM[&quot;Greenwich&quot;,0,AUTHORITY[&quot;EPSG&quot;,&quot;8901&quot;]],UNIT[&quot;degree&quot;,0.0174532925199433,AUTHORITY[&quot;EPSG&quot;,&quot;9122&quot;]],AXIS[&quot;Latitude&quot;,NORTH],AXIS[&quot;Longitude&quot;,EAST],AUTHORITY[&quot;EPSG&quot;,&quot;4326&quot;]]</dd><dt><span>semi_major_axis :</span></dt><dd>6378137.0</dd><dt><span>semi_minor_axis :</span></dt><dd>6356752.314245179</dd><dt><span>inverse_flattening :</span></dt><dd>298.257223563</dd><dt><span>reference_ellipsoid_name :</span></dt><dd>WGS 84</dd><dt><span>longitude_of_prime_meridian :</span></dt><dd>0.0</dd><dt><span>prime_meridian_name :</span></dt><dd>Greenwich</dd><dt><span>geographic_crs_name :</span></dt><dd>WGS 84</dd><dt><span>horizontal_datum_name :</span></dt><dd>World Geodetic System 1984</dd><dt><span>grid_mapping_name :</span></dt><dd>latitude_longitude</dd><dt><span>spatial_ref :</span></dt><dd>GEOGCS[&quot;WGS 84&quot;,DATUM[&quot;WGS_1984&quot;,SPHEROID[&quot;WGS 84&quot;,6378137,298.257223563,AUTHORITY[&quot;EPSG&quot;,&quot;7030&quot;]],AUTHORITY[&quot;EPSG&quot;,&quot;6326&quot;]],PRIMEM[&quot;Greenwich&quot;,0,AUTHORITY[&quot;EPSG&quot;,&quot;8901&quot;]],UNIT[&quot;degree&quot;,0.0174532925199433,AUTHORITY[&quot;EPSG&quot;,&quot;9122&quot;]],AXIS[&quot;Latitude&quot;,NORTH],AXIS[&quot;Longitude&quot;,EAST],AUTHORITY[&quot;EPSG&quot;,&quot;4326&quot;]]</dd><dt><span>GeoTransform :</span></dt><dd>4.0 0.00712500000000027 0.0 52.55 0.0 0.007125000000002046</dd></dl></div><div class='xr-var-data'><pre>array(0)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-0a47eadd-c3ec-4e6e-977d-bafb9f33d118' class='xr-section-summary-in' type='checkbox'  checked><label for='section-0a47eadd-c3ec-4e6e-977d-bafb9f33d118' class='xr-section-summary' >Data variables: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>__xarray_dataarray_variable__</span></div><div class='xr-var-dims'>(time, y, x)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>13.12 13.84 14.15 ... nan nan nan</div><input id='attrs-2c954dd1-0f06-47c7-ab6a-b879e8a9351a' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-2c954dd1-0f06-47c7-ab6a-b879e8a9351a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-04df8b08-c917-48ab-9151-fdb81ffee961' class='xr-var-data-in' type='checkbox'><label for='data-04df8b08-c917-48ab-9151-fdb81ffee961' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[[13.11624842, 13.83797535, 14.14891062, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [14.65302026, 16.1608631 , 16.61562403, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [14.72381326, 16.65569715, 17.2191157 , ...,         nan,\n",
              "                 nan,         nan],\n",
              "        ...,\n",
              "        [ 4.26680681,  4.26680681,  4.06540924, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [ 4.13562629,  4.13562629,  3.99940504, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [ 3.87451541,  3.87451541,  3.85338212, ...,         nan,\n",
              "                 nan,         nan]],\n",
              "\n",
              "       [[16.75896642, 17.13985007, 17.37049601, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [16.57327948, 16.99736228, 17.20226473, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [16.35282672, 16.72540894, 16.98985375, ...,         nan,\n",
              "                 nan,         nan],\n",
              "...\n",
              "        [ 4.13327177,  4.13327177,  4.18327016, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [ 3.99277045,  3.99277045,  3.98168544, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [ 3.96134396,  3.96134396,  4.00772118, ...,         nan,\n",
              "                 nan,         nan]],\n",
              "\n",
              "       [[13.24514401, 14.01932499, 14.3561128 , ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [14.89466024, 16.40358946, 16.84543872, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [14.97016808, 16.94644096, 17.48651524, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        ...,\n",
              "        [ 4.26709174,  4.26709174,  4.06558651, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [ 4.13577656,  4.13577656,  3.99944477, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [ 3.87433358,  3.87433358,  3.85302718, ...,         nan,\n",
              "                 nan,         nan]]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>SPM</span></div><div class='xr-var-dims'>(time, y, x)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>1.118 1.141 1.151 ... nan nan nan</div><input id='attrs-382e6671-3f43-4f1f-bdb4-9ac2e2e0dd16' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-382e6671-3f43-4f1f-bdb4-9ac2e2e0dd16' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ef2847a9-f147-47b6-afbe-87e0492723b7' class='xr-var-data-in' type='checkbox'><label for='data-ef2847a9-f147-47b6-afbe-87e0492723b7' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[[1.11780963, 1.14107255, 1.150723  , ...,        nan,\n",
              "                nan,        nan],\n",
              "        [1.16592715, 1.20846455, 1.22051666, ...,        nan,\n",
              "                nan,        nan],\n",
              "        [1.1680203 , 1.22156282, 1.23601084, ...,        nan,\n",
              "                nan,        nan],\n",
              "        ...,\n",
              "        [0.63010298, 0.63010298, 0.60910427, ...,        nan,\n",
              "                nan,        nan],\n",
              "        [0.61654129, 0.61654129, 0.60199539, ...,        nan,\n",
              "                nan,        nan],\n",
              "        [0.58821739, 0.58821739, 0.58584208, ...,        nan,\n",
              "                nan,        nan]],\n",
              "\n",
              "       [[1.22424723, 1.23400702, 1.23981222, ...,        nan,\n",
              "                nan,        nan],\n",
              "        [1.21940845, 1.23038153, 1.23558563, ...,        nan,\n",
              "                nan,        nan],\n",
              "        [1.21359283, 1.22337675, 1.23018964, ...,        nan,\n",
              "                nan,        nan],\n",
              "...\n",
              "        [0.61629396, 0.61629396, 0.62151591, ...,        nan,\n",
              "                nan,        nan],\n",
              "        [0.60127434, 0.60127434, 0.60006695, ...,        nan,\n",
              "                nan,        nan],\n",
              "        [0.59784255, 0.59784255, 0.6028975 , ...,        nan,\n",
              "                nan,        nan]],\n",
              "\n",
              "       [[1.12205668, 1.1467271 , 1.15703686, ...,        nan,\n",
              "                nan,        nan],\n",
              "        [1.1730306 , 1.21493889, 1.22648233, ...,        nan,\n",
              "                nan,        nan],\n",
              "        [1.17522668, 1.2290785 , 1.24270327, ...,        nan,\n",
              "                nan,        nan],\n",
              "        ...,\n",
              "        [0.63013198, 0.63013198, 0.60912321, ...,        nan,\n",
              "                nan,        nan],\n",
              "        [0.61655707, 0.61655707, 0.6019997 , ...,        nan,\n",
              "                nan,        nan],\n",
              "        [0.58819701, 0.58819701, 0.58580207, ...,        nan,\n",
              "                nan,        nan]]])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-c0aec6e6-e55c-4961-871b-af86ce3cb791' class='xr-section-summary-in' type='checkbox'  ><label for='section-c0aec6e6-e55c-4961-871b-af86ce3cb791' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-553f535f-214b-46f0-942c-3b869159a321' class='xr-index-data-in' type='checkbox'/><label for='index-553f535f-214b-46f0-942c-3b869159a321' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2016-01-01&#x27;, &#x27;2016-01-02&#x27;, &#x27;2016-01-03&#x27;, &#x27;2016-01-04&#x27;,\n",
              "               &#x27;2016-01-05&#x27;, &#x27;2016-01-06&#x27;, &#x27;2016-01-07&#x27;, &#x27;2016-01-08&#x27;,\n",
              "               &#x27;2016-01-09&#x27;, &#x27;2016-01-10&#x27;,\n",
              "               ...\n",
              "               &#x27;2017-12-23&#x27;, &#x27;2017-12-24&#x27;, &#x27;2017-12-25&#x27;, &#x27;2017-12-26&#x27;,\n",
              "               &#x27;2017-12-27&#x27;, &#x27;2017-12-28&#x27;, &#x27;2017-12-29&#x27;, &#x27;2017-12-30&#x27;,\n",
              "               &#x27;2017-12-31&#x27;, &#x27;2018-01-01&#x27;],\n",
              "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, length=732, freq=None))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>y</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-a0a15fa5-b472-4a92-aa9f-fd976853adff' class='xr-index-data-in' type='checkbox'/><label for='index-a0a15fa5-b472-4a92-aa9f-fd976853adff' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([        52.5535625,         52.5606875,         52.5678125,\n",
              "              52.574937500000004, 52.582062500000006,  52.58918750000001,\n",
              "               52.59631250000001,  52.60343750000001, 52.610562500000015,\n",
              "               52.61768750000002,\n",
              "              ...\n",
              "               53.90731250000039,  53.91443750000039,  53.92156250000039,\n",
              "               53.92868750000039, 53.935812500000395,   53.9429375000004,\n",
              "                53.9500625000004,   53.9571875000004,   53.9643125000004,\n",
              "              53.971437500000405],\n",
              "             dtype=&#x27;float64&#x27;, name=&#x27;y&#x27;, length=200))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>x</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-6a263881-5016-4e56-a93c-94de38720427' class='xr-index-data-in' type='checkbox'/><label for='index-6a263881-5016-4e56-a93c-94de38720427' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([         4.0035625,          4.0106875,  4.017812500000001,\n",
              "               4.024937500000001,  4.032062500000001, 4.0391875000000015,\n",
              "               4.046312500000002,  4.053437500000002,  4.060562500000002,\n",
              "               4.067687500000003,\n",
              "              ...\n",
              "               7.366562500000128,  7.373687500000128,  7.380812500000128,\n",
              "               7.387937500000128,  7.395062500000129,  7.402187500000129,\n",
              "               7.409312500000129, 7.4164375000001295,   7.42356250000013,\n",
              "                7.43068750000013],\n",
              "             dtype=&#x27;float64&#x27;, name=&#x27;x&#x27;, length=482))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-41d86201-592b-4c5c-bf15-9ae300f629d0' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-41d86201-592b-4c5c-bf15-9ae300f629d0' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## creating the land mask (with the islands)\n",
        "bool_mask = np.isnan(data_isl_mask['SPM'][5,:,:])\n",
        "mask_new = np.where(bool_mask == True, np.nan, 1.)\n",
        "plt.imshow(mask_new, origin = 'lower')\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "XOOYrc1ZOnmv",
        "outputId": "0ea513fd-0080-4b44-80dd-d56cd9efb27b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x79392d37bd00>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAGTCAYAAAD+/cJkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+U0lEQVR4nO3de1xVdaL///dG41IIDopcEhPpol3ESZP45ZgmJ0QfnTSmRxfnRGr6tS/4GKWOEzOMmqfvjxnnlFqRNlPJlHosZ8o5qUM/xMTxEVpSfLvqI43ClI1dDmyluMhevz8cVu5AZbEXbDb79Xw81uPhXvuz1v7sJbLefm7LYRiGIQAAgB4W5OsKAACAwEQIAQAAPkEIAQAAPkEIAQAAPkEIAQAAPkEIAQAAPkEIAQAAPkEIAQAAPkEIAQAAPkEIAQAAPkEIAQDAT+3Zs0e33Xab4uPj5XA4tHXr1vOWr6mp0b333qsrr7xSQUFBWrRoUYfltmzZopEjRyo0NFTXXXedduzY4fG+YRhaunSp4uLiFBYWprS0NH366aeW608IAQDATzU0NCg5OVmFhYWdKt/U1KTo6Gjl5+crOTm5wzJvvfWW7rnnHs2dO1fvvfeeZsyYoRkzZujDDz80y6xcuVJPPvmk1q1bp/379+uSSy5Renq6GhsbLdXfwQPsAADwfw6HQ6+99ppmzJjRqfKTJk3SmDFjtHr1ao/9d911lxoaGrRt2zZz34033qgxY8Zo3bp1MgxD8fHxeuihh/Twww9Lkurr6xUTE6OioiLdfffdna5z/06XBAAA59TY2Kjm5mavz2MYhhwOh8e+kJAQhYSEeH3uzigvL1dubq7HvvT0dLOrp6qqSk6nU2lpaeb7kZGRSklJUXl5OSEEAICe1NjYqMTLwuU80er1ucLDw3Xq1CmPfcuWLdPy5cu9PndnOJ1OxcTEeOyLiYmR0+k032/bd64ynUUIAQDAS83NzXKeaFVVxWWKGND14Zauk24ljv1CR48eVUREhLm/p1pBehohBAAAm0QMCPIqhJjniYjwCCE9KTY2VrW1tR77amtrFRsba77fti8uLs6jzJgxYyx9FrNjAACwSavh9nrztdTUVJWWlnrsKykpUWpqqiQpMTFRsbGxHmVcLpf2799vluksWkIAALCJW4bc6vqkU6vHnjp1SocPHzZfV1VVqbKyUlFRURo2bJjy8vJ07Ngxvfjii2aZyspK89ivvvpKlZWVCg4O1tVXXy1J+uUvf6mbb75Zjz/+uKZPn67NmzfrwIED+uMf/yjpzCycRYsW6bHHHtMVV1yhxMRE/fa3v1V8fHynZ+a0YYouAABecrlcioyMlPPQMK/HhMReVa36+vpOdcfs3r1bkydPbrc/KytLRUVFuv/++/X5559r9+7d5ns/nnkjSZdddpk+//xz8/WWLVuUn5+vzz//XFdccYVWrlypadOmme8bhqFly5bpj3/8o+rq6jRhwgQ988wzuvLKKy19X0IIAABeagshxw8N9TqExF/1ZadDiL+jOwYAAJu0GoZavfi/vTfH+iMGpgIAAJ+gJQQAAJv09MBUf0cIAQDAJm4ZaiWEdBohBAAAm9ASYg1jQgAAgE/QEgIAgE2YHWMNIQQAAJu4/7l5c3wgoTsGAAD4BC0hAADYpNXL2THeHOuPCCEAANik1TizeXN8IKE7BgAA+AQtIQAA2ISBqdYQQgAAsIlbDrXK4dXxgYTuGAAA4BO0hAAAYBO3cWbz5vhAQggBAMAmrV52x3hzrD8ihAAAYBNCiDWMCQEAAD5BSwgAADZxGw65DS9mx3hxrD8ihAAAYBO6Y6yhOwYAAPgELSEAANikVUFq9eL/96021sUfEEIAALCJ4eWYECPAxoTQHQMAAHyClhAAAGzCwFRrCCEAANik1QhSq+HFmJAAW7ad7hgAAOATtIQAAGATtxxye/H/e7cCqymEEAIAgE0YE2INIQQAAJt4PyYksFpCGBMCAAB8gpYQAABscmZMiBcPsKM7BgAAdIXby2XbA21gKt0xAADAJwghAADYpG1gqjebFXv27NFtt92m+Ph4ORwObd269YLH7N69W9dff71CQkJ0+eWXq6ioyOP94cOHy+FwtNuys7PNMpMmTWr3/oIFCyzVXSKEAABgG7eCvN6saGhoUHJysgoLCztVvqqqStOnT9fkyZNVWVmpRYsW6YEHHtAbb7xhlnnnnXdUU1NjbiUlJZKkO++80+Nc8+bN8yi3cuVKS3WXGBMCAIDfysjIUEZGRqfLr1u3TomJiXr88cclSaNGjdLevXu1atUqpaenS5Kio6M9jvnd736npKQk3XzzzR77L774YsXGxnpVf1pCAACwSavh8HqTJJfL5bE1NTXZUr/y8nKlpaV57EtPT1d5eXmH5Zubm7VhwwbNmTNHDofnzJ2NGzdq8ODBuvbaa5WXl6fvvvvOcn1oCQEAwCatXs6Oaf3n7JiEhASP/cuWLdPy5cu9qZokyel0KiYmxmNfTEyMXC6Xvv/+e4WFhXm8t3XrVtXV1en+++/32H/vvffqsssuU3x8vN5//3396le/0qFDh/Tqq69aqg8hBACAXubo0aOKiIgwX4eEhPikHs8//7wyMjIUHx/vsX/+/Pnmn6+77jrFxcVpypQpOnLkiJKSkjp9fkIIAAA2cRtBcnuxbLv7n8u2R0REeIQQu8TGxqq2ttZjX21trSIiItq1gnzxxRfauXNnp1o3UlJSJEmHDx8mhAAA4At2dcd0l9TUVO3YscNjX0lJiVJTU9uVXb9+vYYMGaLp06df8LyVlZWSpLi4OEv1IYQAAGATt2QOLu3q8VacOnVKhw8fNl9XVVWpsrJSUVFRGjZsmPLy8nTs2DG9+OKLkqQFCxbo6aef1pIlSzRnzhzt2rVLr7zyirZv3+5ZD7db69evV1ZWlvr394wKR44c0aZNmzRt2jQNGjRI77//vhYvXqyJEydq9OjRlupPCAEAwE8dOHBAkydPNl/n5uZKkrKyslRUVKSamhpVV1eb7ycmJmr79u1avHix1qxZo6FDh+q5554zp+e22blzp6qrqzVnzpx2nxkcHKydO3dq9erVamhoUEJCgjIzM5Wfn2+5/g7DCLDnBgMAYDOXy6XIyEitffcGhYV3/f/33586rQevf0f19fXdMiakt6ElBAAAm3Rl6fUfHx9IAuvbAgCAXoOWEAAAbOKWQ255MzC168f6I0IIAAA2oTvGmsD6tgAAoNegJQQAAJt4v1hZYLUNEEIAALCJ23DI7c1iZV4c648CK3IBAIBeg5YQAABs4vayO8YdYG0DhBAAAGzi/VN0CSEAAKALWuVQqxdrfXhzrD8KrMgFAAB6DVpCAACwCd0x1hBCAACwSau861Jpta8qfiGwIhcAAOg1aAkBAMAmdMdYQwgBAMAmPMDOmsD6tgAAoNegJQQAAJsYcsjtxcBUI8DWCSGEAABgE7pjrAmsbwsAAHoNWkIAALCJ23DIbXS9S8WbY/0RIQQAAJu0evkUXW+O9UeEEAAAbEJLiDWBFbkAAECvQUsIAAA2cStIbi/+f+/Nsf6IEAIAgE1aDYdavehS8eZYfxRYkQsAAPQatIQAAGATBqZaQwgBAMAmhpdP0TVYMRUAAKD70RICAIBNWuVQqxcPofPmWH9ECAEAwCZuw7txHW7Dxsr4AbpjAACAT9ASAgCATdxeDkz15lh/FFjfFgCAbuSWw+vNij179ui2225TfHy8HA6Htm7desFjdu/ereuvv14hISG6/PLLVVRU5PH+8uXL5XA4PLaRI0d6lGlsbFR2drYGDRqk8PBwZWZmqra21lLdJUIIAAC2aVsx1ZvNioaGBiUnJ6uwsLBT5auqqjR9+nRNnjxZlZWVWrRokR544AG98cYbHuWuueYa1dTUmNvevXs93l+8eLFef/11bdmyRWVlZTp+/LjuuOMOS3WX6I4BAMBvZWRkKCMjo9Pl161bp8TERD3++OOSpFGjRmnv3r1atWqV0tPTzXL9+/dXbGxsh+eor6/X888/r02bNumWW26RJK1fv16jRo3Svn37dOONN3a6PrSEAABgk7YxId5skuRyuTy2pqYmW+pXXl6utLQ0j33p6ekqLy/32Pfpp58qPj5eI0aM0KxZs1RdXW2+V1FRoZaWFo/zjBw5UsOGDWt3ngshhAAAYBO3HObS7V3a/jkmJCEhQZGRkeZWUFBgS/2cTqdiYmI89sXExMjlcun777+XJKWkpKioqEjFxcVau3atqqqq9LOf/UwnT540zxEcHKyBAwe2O4/T6bRUH7pjAADoZY4ePaqIiAjzdUhISI999tndO6NHj1ZKSoouu+wyvfLKK5o7d66tn0UIAQDAJkYXZrj8+HhJioiI8AghdomNjW03i6W2tlYREREKCwvr8JiBAwfqyiuv1OHDh81zNDc3q66uzqM1pLa29pzjSM6F7hgAAGziVVeMl0/g7YzU1FSVlpZ67CspKVFqauo5jzl16pSOHDmiuLg4SdLYsWN10UUXeZzn0KFDqq6uPu95OkJLCAAAfurUqVNmC4V0ZgpuZWWloqKiNGzYMOXl5enYsWN68cUXJUkLFizQ008/rSVLlmjOnDnatWuXXnnlFW3fvt08x8MPP6zbbrtNl112mY4fP65ly5apX79+uueeeyRJkZGRmjt3rnJzcxUVFaWIiAgtXLhQqamplmbGSIQQAABs09Mrph44cECTJ082X+fm5kqSsrKyVFRUpJqaGo+ZLYmJidq+fbsWL16sNWvWaOjQoXruuec8pud++eWXuueee/TNN98oOjpaEyZM0L59+xQdHW2WWbVqlYKCgpSZmammpialp6frmWeesfx9HYZhBNjjcgAAsJfL5VJkZKRu///m6KJLgrt8npaGZv3t1hdUX1/fLWNCehvGhAAAAJ+gOwYAAJt05fkvPz4+kPhlCHG73Tp+/LgGDBgghyOw/sIAANYYhqGTJ08qPj5eQUHd2wHg7QyX7p4d09v4ZQg5fvy4EhISfF0NAIAfOXr0qIYOHdqtn0EIscYvQ8iAAQMkSUOX5SsoNNTHtQEA9BYf/O+F7fa5XC4lJCSY9w70Hn4ZQtq6YIJCQwkhAADT+WaU9ET3PS0h1vhlCAEAoDcihFjDFF0AAOATtIQAAGATQ95Nsw201UMJIQAA2ITuGGvojgEAAD5BSwgAADahJcQaQggAADYhhFhDdwwAAPAJWkIAALAJLSHWEEIAALCJYThkeBEkvDnWHxFCAACwiVsOr9YJ8eZYf8SYEAAA4BO0hAAAYBPGhFhDCAEAwCaMCbGG7hgAAOATtIQAAGATumOsIYQAAGATumOsoTsGAAD4BC0hAADYxPCyOybQWkIIIQAA2MSQZBjeHR9I6I4BAAA+QUsIAAA2ccshB8u2dxohBAAAmzA7xhpCCAAANnEbDjlYJ6TTGBMCAAB8gpYQAABsYhhezo4JsOkxhBAAAGzCmBBr6I4BAAA+QUsIAAA2oSXEGkIIAAA2YXaMNXTHAADgp/bs2aPbbrtN8fHxcjgc2rp16wWP2b17t66//nqFhITo8ssvV1FRkcf7BQUFuuGGGzRgwAANGTJEM2bM0KFDhzzKTJo0SQ6Hw2NbsGCB5frTEgIA8AtVix7ydRUuqKdnxzQ0NCg5OVlz5szRHXfcccHyVVVVmj59uhYsWKCNGzeqtLRUDzzwgOLi4pSeni5JKisrU3Z2tm644QadPn1av/71r3Xrrbfq448/1iWXXGKea968eVqxYoX5+uKLL7ZWeRFCAAC9iD8EjfM5E0K8GRNirXxGRoYyMjI6XX7dunVKTEzU448/LkkaNWqU9u7dq1WrVpkhpLi42OOYoqIiDRkyRBUVFZo4caK5/+KLL1ZsbKy1Cv8I3TEAAJ+rWvSQ3wcQ6YeBqd5skuRyuTy2pqYmW+pXXl6utLQ0j33p6ekqLy8/5zH19fWSpKioKI/9Gzdu1ODBg3XttdcqLy9P3333neX6WA4hF+p/uv/++9v1E02dOtWjzLfffqtZs2YpIiJCAwcO1Ny5c3Xq1CnLlQcA+J+2wHH2Bk8JCQmKjIw0t4KCAlvO63Q6FRMT47EvJiZGLpdL33//fbvybrdbixYt0k033aRrr73W3H/vvfdqw4YNevPNN5WXl6eXXnpJv/jFLyzXx3J3TGf6n6ZOnar169ebr0NCQjzenzVrlmpqalRSUqKWlhbNnj1b8+fP16ZNm6xWBwDgR/p64DD+uXlzvCQdPXpUERER5v4f30d7SnZ2tj788EPt3bvXY//8+fPNP1933XWKi4vTlClTdOTIESUlJXX6/JZDSGf6n0JCQs7ZT/TJJ5+ouLhY77zzjsaNGydJeuqppzRt2jT953/+p+Lj461WCQCAXsGudUIiIiI8QohdYmNjVVtb67GvtrZWERERCgsL89ifk5Ojbdu2ac+ePRo6dOh5z5uSkiJJOnz4cPeGkM7YvXu3hgwZop/85Ce65ZZb9Nhjj2nQoEGSzvRHDRw40AwgkpSWlqagoCDt379fM2fObHe+pqYmj/4wl8vVHdUGAHSDvt764U9SU1O1Y8cOj30lJSVKTU01XxuGoYULF+q1117T7t27lZiYeMHzVlZWSpLi4uIs1cf2galTp07Viy++qNLSUv3+979XWVmZMjIy1NraKulMf9SQIUM8junfv7+ioqLkdDo7PGdBQYFH31hCQoLd1QYAdIOACyCGDZsFp06dUmVlpRkCqqqqVFlZqerqaklSXl6e7rvvPrP8ggUL9Nlnn2nJkiU6ePCgnnnmGb3yyitavHixWSY7O1sbNmzQpk2bNGDAADmdTjmdTnPMyJEjR/Qf//Efqqio0Oeff67//u//1n333aeJEydq9OjRlupve0vI3Xffbf75uuuu0+jRo5WUlKTdu3drypQpXTpnXl6ecnNzzdcul4sgAgC9WMCFjzZedsfI4rEHDhzQ5MmTzddt98qsrCwVFRWppqbGDCSSlJiYqO3bt2vx4sVas2aNhg4dqueee86cnitJa9eulXRmQbKzrV+/Xvfff7+Cg4O1c+dOrV69Wg0NDUpISFBmZqby8/OtftvuXydkxIgRGjx4sA4fPqwpU6YoNjZWJ06c8Chz+vRpffvtt+ccRxISEuKzQTkAgM4L2PDhI5MmTZJxnsVFfrwaatsx77333jmPOd/5pDMzd8rKyjpdx/Pp9nVCvvzyS33zzTdmP1Fqaqrq6upUUVFhltm1a5fcbrc5sAUA4H8IID+smOrNFkgst4ScOnVKhw8fNl+39T9FRUUpKipKjz76qDIzMxUbG6sjR45oyZIluvzyy82mnlGjRmnq1KmaN2+e1q1bp5aWFuXk5Ojuu+9mZgwA+CkCyBk8Rdcayy0hBw4c0E9/+lP99Kc/lXSm/+mnP/2pli5dqn79+un999/Xv/7rv+rKK6/U3LlzNXbsWP3jH//w6E7ZuHGjRo4cqSlTpmjatGmaMGGC/vjHP9r3rQAAPYYAgq6y3BJyof6nN95444LniIqKYmEyAEDfYzgsDy5td3wA4QF2AHABP/6ffuLqx31Uk97px9cjkFtGevopuv6OB9gBgEWBfJPtjMTVjwduUOvhdUL8HSEEALqAB69dWMAGEXQa3TEA0E3aQkpfuRl3FLrO990CMaQxO8YaQggAdEFfCRbdJRADiCnAulS8QQgBEBC8GVza1cDR14JK4urH213HgA4b8BohBECvxM2td+ooiOAHdMdYQwgB0Kt05w2ur7VM+AIB5AK8neESYF05hBAAvUZ33OAIHvYgfKA7EEIAdItz3bS6OxQQOuBbjn9u3hwfOAghgB/ozP9C7br5dvV/vD118ydkoFejO8YSQgjQi1kJBP7QXG41QARS4OjK318gXR/0TYQQoJv1ZCuGL5yr7h09T6Rq0UOd/q7+fE3Ox86wyDNteiFaQiwhhAA284cWCavoavFOT/1MnO9z+uq17XV4iq4lhBDAS97eYOy+OXR0vrPr6KubUaDdBPtSGO1L36W78RRdawghgEV2/kK+0I257X1vu3QCLQDYjZsw0D0IIcA52H3j8SYIECK6H0EDtmBMiCWEEAScnr7ZBGKAsHKNu3MZ8I4GxwLdijEhlhBC0Kdx0+kZ3lzn7vw74u//B1ZmJgE9hRCCPqun/ncdaLix+y+CSPdzGGc2b44PJIQQ9Ek8g8QeBA7AIsaEWEIIQZ9C+LAH4QNt+FlAdyKEoM+w45dlIAYOiRtNILHSJcPPRRcwMNUSQggCTqAGjR/jBgN0A7pjLAnydQUAu1xosa62DQSQQNfZv3/+vaC70RKCPoVfmudG8MDZ2n4eOrNqLz87FtASYgkhBOhDOnqqKjcQnE9nwsiFnkeEsxBCLCGEAH7Gyi9/bhTorI4C7Pl0V6uj3//MMjDVEkII0Iv5/S9k+K3OdtcA3iCEoFc63823r/9SJHigN+no5/Hsf4N2hpW+8LPPiqnWWA4he/bs0R/+8AdVVFSopqZGr732mmbMmGG+bxiGli1bpj/96U+qq6vTTTfdpLVr1+qKK64wy3z77bdauHChXn/9dQUFBSkzM1Nr1qxReHi4LV8K/snqL6AL/XL0N33hFzACAz+r58GYEEssT9FtaGhQcnKyCgsLO3x/5cqVevLJJ7Vu3Trt379fl1xyidLT09XY2GiWmTVrlj766COVlJRo27Zt2rNnj+bPn9/1bwG/VLXoIY/tfH48xbav/RLsa98HsIp/A12zZ88e3XbbbYqPj5fD4dDWrVsveMzu3bt1/fXXKyQkRJdffrmKioralSksLNTw4cMVGhqqlJQUvf322x7vNzY2Kjs7W4MGDVJ4eLgyMzNVW1truf6WQ0hGRoYee+wxzZw5s917hmFo9erVys/P1+23367Ro0frxRdf1PHjx80L88knn6i4uFjPPfecUlJSNGHCBD311FPavHmzjh8/bvkLwP90JnS0sbK2h7+2gvDLF0BXXahh4Meqqqo0ffp0TZ48WZWVlVq0aJEeeOABvfHGG2aZl19+Wbm5uVq2bJneffddJScnKz09XSdOnDDLLF68WK+//rq2bNmisrIyHT9+XHfccYfl+ts6JqSqqkpOp1NpaWnmvsjISKWkpKi8vFx33323ysvLNXDgQI0bN84sk5aWpqCgIO3fv7/DcNPU1KSmpibztcvlsrPa6CGdudn29cBxNsIH+oq+8O/RLg55OSbEYvmMjAxlZGR0uvy6deuUmJioxx8/83c2atQo7d27V6tWrVJ6erok6YknntC8efM0e/Zs85jt27frhRde0COPPKL6+no9//zz2rRpk2655RZJ0vr16zVq1Cjt27dPN954Y6frY+uKqU6nU5IUExPjsT8mJsZ8z+l0asiQIR7v9+/fX1FRUWaZHysoKFBkZKS5JSQk2Flt9IDOdrcECgIIgPNxuVwe29n/EfdGeXm5R0OBJKWnp6u8vFyS1NzcrIqKCo8yQUFBSktLM8tUVFSopaXFo8zIkSM1bNgws0xn+cXsmLy8POXm5pqvXS4XQcRP9MabrdX1ELrzs4G+gOm8Z7FpnZAf3+OWLVum5cuXe1GxM5xOZ4cNBS6XS99//73+53/+R62trR2WOXjwoHmO4OBgDRw4sF2ZczUmnIutISQ2NlaSVFtbq7i4OHN/bW2txowZY5Y5u19Jkk6fPq1vv/3WPP7HQkJCFBISYmdV0U26cpPt67+4CB4IFF2dsdan/o3YNDvm6NGjioiIMHf31XugrSEkMTFRsbGxKi0tNUOHy+XS/v379eCDD0qSUlNTVVdXp4qKCo0dO1aStGvXLrndbqWkpNhZHfQwfwkgPfWZfeoXK9BF/DvomoiICI8QYpfY2Nh2s1hqa2sVERGhsLAw9evXT/369euwTFtDQWxsrJqbm1VXV+fRGnJ2mc6yHEJOnTqlw4cPm6+rqqpUWVmpqKgoDRs2TIsWLdJjjz2mK664QomJifrtb3+r+Ph4cy2RUaNGaerUqZo3b57WrVunlpYW5eTk6O6771Z8fLzV6sDHrP6C6eutHhK/dIHeJHH14/q/c+b13Af28nVCUlNTtWPHDo99JSUlSk1NlSQFBwdr7NixKi0tNe/bbrdbpaWlysnJkSSNHTtWF110kUpLS5WZmSlJOnTokKqrq83zdJblEHLgwAFNnjzZfN02ViMrK0tFRUVasmSJGhoaNH/+fNXV1WnChAkqLi5WaGioeczGjRuVk5OjKVOmmIuVPfnkk1arAh+zcrMNhPABoPepWvRQj86o7OkVUy/UMJCXl6djx47pxRdflCQtWLBATz/9tJYsWaI5c+Zo165deuWVV7R9+3bzHLm5ucrKytK4ceM0fvx4rV69Wg0NDeZsmcjISM2dO1e5ubmKiopSRESEFi5cqNTUVEszY6QuhJBJkybJMM59lRwOh1asWKEVK1acs0xUVJQ2bdpk9aPhBzpaTCyQAgitIECA6+GWkAs1DNTU1Ki6utp8PzExUdu3b9fixYu1Zs0aDR06VM8995w5PVeS7rrrLn311VdaunSpnE6nxowZo+LiYo/BqqtWrTIbEZqampSenq5nnnnG8td1GOdLFL2Uy+VSZGSkhhU8pqCzWljQ8wI1bHSEAAL0Tm33jPr6+m4ZZ3H2Zwx/7P94dV9yNzbq8/zfdGtdexO/mKKL3ivQgwcAeOjlY0J6G0IIuoxWkDNoAQHQhqfoWmPriqkIHD++8QbqjThQvzcA2IGWEFhyvptu1aKHArpFBADsWjE1UBBC0Cmd/R8/yzcDCGiMCbGE7hgAAOAThBBcUFfGPTBWAkAgahuY6s0WSOiOwXkRJgDAArpjLCGEoEOEjwvjGgGAdwgh6BZ9eWAq4QPAOXnbpUJLCAIdN1kA6CK6YywhhMADAeT8uD4AzosQYgmzY2DiBgsA6Em0hIDwcQ5cFwBW8ewYawghgAgcAOALhBDYxl9nxBBAAMA3CCEIaAQQALZiYKolhJAAF4g34UD8zgB6BmNCrCGEwBa9vSuG4AEAvQ8hBF7p7eFDIoAA6GEB1prhDUIILPGH0HE2AgiAHsWYEEsIIeiTCB8A0PsRQtAp/tACQvAA4GsMTLWGEII+gQACoFegO8YSQkiAS1z9uMcN3B9aPM5G+ADQm9ASYg0hpI+70E06cfXjfhc82hBAAMC/EULgdwgfAHotumMsIYQEoB+3fHSmtcTXCB4A/AIhxBJCSB9nR4CoWvSQz4II4QMA+i5CCHolwgcAf8TAVGtsDyHLly/Xo48+6rHvqquu0sGDByVJjY2Neuihh7R582Y1NTUpPT1dzzzzjGJiYuyuCnopAgaAPovuGEuCuuOk11xzjWpqasxt79695nuLFy/W66+/ri1btqisrEzHjx/XHXfc0R3VgI0IDgAAu3VLd0z//v0VGxvbbn99fb2ef/55bdq0Sbfccoskaf369Ro1apT27dunG2+8scPzNTU1qampyXztcrm6o9q4AG/HhhBkAPR5tIRY0i0h5NNPP1V8fLxCQ0OVmpqqgoICDRs2TBUVFWppaVFaWppZduTIkRo2bJjKy8vPGUIKCgradfHAN7qysBnhA0CgYEyINbZ3x6SkpKioqEjFxcVau3atqqqq9LOf/UwnT56U0+lUcHCwBg4c6HFMTEyMnE7nOc+Zl5en+vp6czt69Kjd1Q5Y3gSEqkUPXfB4AggA4FxsDyEZGRm68847NXr0aKWnp2vHjh2qq6vTK6+80uVzhoSEKCIiwmND73F2GGn7c2cCCgD0OYYNWxcUFhZq+PDhCg0NVUpKit5+++1zlm1padGKFSuUlJSk0NBQJScnq7i42KPM8OHD5XA42m3Z2dlmmUmTJrV7f8GCBZbq3S0DU882cOBAXXnllTp8+LBiY2PV3Nysuro6jzK1tbUdjiFB97I7JBA6AAS6tu4YbzarXn75ZeXm5mrZsmV69913lZycrPT0dJ04caLD8vn5+Xr22Wf11FNP6eOPP9aCBQs0c+ZMvffee2aZd955x2OCSUlJiSTpzjvv9DjXvHnzPMqtXLnSUt27PYScOnVKR44cUVxcnMaOHauLLrpIpaWl5vuHDh1SdXW1UlNTu7sqAAB0Lx+0hDzxxBOaN2+eZs+erauvvlrr1q3TxRdfrBdeeKHD8i+99JJ+/etfa9q0aRoxYoQefPBBTZs2TY8//sM4v+joaMXGxprbtm3blJSUpJtvvtnjXBdffLFHOas9FbaHkIcfflhlZWX6/PPP9dZbb2nmzJnq16+f7rnnHkVGRmru3LnKzc3Vm2++qYqKCs2ePVupqannHJQKAECgcblcHtvZM0TP1tzcrIqKCo8JH0FBQUpLS1N5eXmHxzQ1NSk0NNRjX1hYmMdyGj/+jA0bNmjOnDlyOBwe723cuFGDBw/Wtddeq7y8PH333XdWvqb9s2O+/PJL3XPPPfrmm28UHR2tCRMmaN++fYqOjpYkrVq1SkFBQcrMzPRYrAw9i64TAOgGNk3RTUhI8Ni9bNkyLV++vF3xr7/+Wq2tre0W/IyJiTEXCf2x9PR0PfHEE5o4caKSkpJUWlqqV199Va2trR2W37p1q+rq6nT//fd77L/33nt12WWXKT4+Xu+//75+9atf6dChQ3r11Vc7913VDSFk8+bN530/NDRUhYWFKiwstPujAQDwKcc/N2+Ol6SjR496dG2EhIR4Uy0Pa9as0bx58zRy5Eg5HA4lJSVp9uzZ5+y+ef7555WRkaH4+HiP/fPnzzf/fN111ykuLk5TpkzRkSNHlJSU1Km6dPuYEPQ+tIIAQO/24xmh5wohgwcPVr9+/VRbW+ux/3wTPqKjo7V161Y1NDToiy++0MGDBxUeHq4RI0a0K/vFF19o586deuCBBy5Y55SUFEnS4cOHL1i2DSEkwBBAAKAb9fDA1ODgYI0dO9Zjwofb7VZpaekFJ3yEhobq0ksv1enTp/XXv/5Vt99+e7sy69ev15AhQzR9+vQL1qWyslKSFBcX1+n68xRdAABs4osVU3Nzc5WVlaVx48Zp/PjxWr16tRoaGjR79mxJ0n333adLL71UBQUFkqT9+/fr2LFjGjNmjI4dO6bly5fL7XZryZIlHud1u91av369srKy1L+/Z1w4cuSINm3apGnTpmnQoEF6//33tXjxYk2cOFGjR4/udN0JIQAA+LG77rpLX331lZYuXSqn06kxY8aouLjYHKxaXV2toKAfOj4aGxuVn5+vzz77TOHh4Zo2bZpeeumldquZ79y5U9XV1ZozZ067zwwODtbOnTvNwJOQkKDMzEzl5+dbqrvDMAy/W6ne5XIpMjJSwwoeU9CPphnh/OiOARBo2u4Z9fX13bbidttnXPO//l/1C+n6fam1qVEfPfvrbq1rb0JLSAAhgABAD/C7/9r7DgNTAwQBBADQ29ASAgCATXwxMNWfEUICAK0gANBDbFoxNVAQQvo4AggA9BxaQqxhTAgAAPAJWkIAALAL3TGWEEIAALAJ3THW0B0DAAB8gpYQAADsQneMJYSQPoyZMQDQwwghltAdAwAAfIKWEAAAbMLAVGsIIQAA2IXuGEvojgEAAD5BS0gfxaBUAOh5DsOQw+h6c4Y3x/ojQggAAHahO8YSQggAADZhYKo1jAkBAAA+QUtIH8R4EADwEbpjLCGEAABgE7pjrKE7BgAA+AQtIQAA2IXuGEsIIX0M40EAwHfojrGG7hgAAOATPg0hhYWFGj58uEJDQ5WSkqK3337bl9UBAMA7hg1bAPFZCHn55ZeVm5urZcuW6d1331VycrLS09N14sQJX1UJAACvtXXJdGULND4LIU888YTmzZun2bNn6+qrr9a6det08cUX64UXXvBVlQAAQA/yycDU5uZmVVRUKC8vz9wXFBSktLQ0lZeXtyvf1NSkpqYm83V9fb0kyd3Y2P2V9SMf/O+Fcrlcvq4GAPQqbb8XjZ54OJxhnNm8OT6A+CSEfP3112ptbVVMTIzH/piYGB08eLBd+YKCAj366KPt9n/56GPdVkd/FJmX7+sqAECvdfLkSUVGRnbrZzA7xhq/mKKbl5en3Nxc87Xb7dYXX3yhMWPG6OjRo4qIiPBh7fyby+VSQkIC19FLXEd7cB3tw7X8gWEYOnnypOLj43vgw8Q6IRb4JIQMHjxY/fr1U21trcf+2tpaxcbGtisfEhKikJAQj31BQWeGs0RERAT8PzA7cB3twXW0B9fRPlzLM7q7BQRd45OBqcHBwRo7dqxKS0vNfW63W6WlpUpNTfVFlQAA8JrD7f0WSHzWHZObm6usrCyNGzdO48eP1+rVq9XQ0KDZs2f7qkoAAHiH7hhLfBZC7rrrLn311VdaunSpnE6nxowZo+Li4naDVc8lJCREy5Yta9dNA2u4jvbgOtqD62gfriX8gcPokTlLAAD0XS6XS5GRkRp/+2Pqf1Fol89zuqVRb/8tX/X19ZbG8hQWFuoPf/iDnE6nkpOT9dRTT2n8+PEdlm1paVFBQYH+/Oc/69ixY7rqqqv0+9//XlOnTjXLLF++vN2s1KuuuspjBmtjY6Meeughbd68WU1NTUpPT9czzzzT6cYEiWfHAABgn7Z1QrzZLLK6Anl+fr6effZZPfXUU/r444+1YMECzZw5U++9955HuWuuuUY1NTXmtnfvXo/3Fy9erNdff11btmxRWVmZjh8/rjvuuMNS3WkJAQDAS2ZLyL/+h/ctIf/9W0stISkpKbrhhhv09NNPSzoz0SMhIUELFy7UI4880q58fHy8fvOb3yg7O9vcl5mZqbCwMG3YsEHSmZaQrVu3qrKyssPPrK+vV3R0tDZt2qSf//znkqSDBw9q1KhRKi8v14033tiputMSAgCATbx5bszZC525XC6P7exVw8/WtgJ5Wlqaue98K5BLZ1YhDw31DEphYWHtWjo+/fRTxcfHa8SIEZo1a5aqq6vN9yoqKtTS0uLxuSNHjtSwYcPO+bkdIYQAAGAXm56im5CQoMjISHMrKCjo8OPOtwK50+ns8Jj09HQ98cQT+vTTT+V2u1VSUqJXX31VNTU1ZpmUlBQVFRWpuLhYa9euVVVVlX72s5/p5MmTkiSn06ng4GANHDiw05/bEb8MIYWFhRo+fLhCQ0OVkpKit99+29dV6lX27Nmj2267TfHx8XI4HNq6davH+4ZhaOnSpYqLi1NYWJjS0tL06aefepT59ttvNWvWLEVERGjgwIGaO3euTp061YPfwvcKCgp0ww03aMCAARoyZIhmzJihQ4cOeZRpbGxUdna2Bg0apPDwcGVmZrZbhK+6ulrTp0/XxRdfrCFDhujf//3fdfr06Z78Kj61du1ajR492lw0KzU1VX//+9/N97mGXfO73/1ODodDixYtMvdxLfuOo0ePqr6+3tzOftaat9asWaMrrrhCI0eOVHBwsHJycjR79mxzEVBJysjI0J133qnRo0crPT1dO3bsUF1dnV555RXb6iH5YQixOgAnEDU0NCg5OVmFhYUdvr9y5Uo9+eSTWrdunfbv369LLrlE6enpajzrgYCzZs3SRx99pJKSEm3btk179uzR/Pnze+or9AplZWXKzs7Wvn37VFJSopaWFt16661qaGgwy1xoYFZra6umT5+u5uZmvfXWW/rzn/+soqIiLV261BdfySeGDh2q3/3ud6qoqNCBAwd0yy236Pbbb9dHH30kiWvYFe+8846effZZjR492mM/19L37OqOaQvtbdu5plpbXYFckqKjo7V161Y1NDToiy++0MGDBxUeHq4RI0ac83sNHDhQV155pQ4fPixJio2NVXNzs+rq6jr9uR0y/Mz48eON7Oxs83Vra6sRHx9vFBQU+LBWvZck47XXXjNfu91uIzY21vjDH/5g7qurqzNCQkKM//qv/zIMwzA+/vhjQ5LxzjvvmGX+/ve/Gw6Hwzh27FiP1b23OXHihCHJKCsrMwzjzHW76KKLjC1btphlPvnkE0OSUV5ebhiGYezYscMICgoynE6nWWbt2rVGRESE0dTU1LNfoBf5yU9+Yjz33HNcwy44efKkccUVVxglJSXGzTffbPzyl780DIOfR1+rr683JBk3TlthTLh9ZZe3G6etMCQZ9fX1nf7s8ePHGzk5Oebr1tZW49JLL+30fbG5udlISkoy8vLyzlnm5MmTxk9+8hNjzZo1hmH88PP2l7/8xSxz8OBBj5+3zvCrlpCuDMCBp6qqKjmdTo9rGBkZqZSUFPMalpeXa+DAgRo3bpxZJi0tTUFBQdq/f3+P17m3qK+vlyRFRUVJ6tzArPLycl133XUe/bXp6elyuVxmS0AgaW1t1ebNm9XQ0KDU1FSuYRdkZ2dr+vTpHtdM4uext7CrJcSK3Nxc/elPf9Kf//xnffLJJ3rwwQc9ViC/7777PLpz9u/fr1dffVWfffaZ/vGPf2jq1Klyu91asmSJWebhhx9WWVmZPv/8c7311luaOXOm+vXrp3vuuUfSmfvG3LlzlZubqzfffFMVFRWaPXu2UlNTOz0zRvKTp+i2Od8AnLMXUMG5tQ0YOt8gJqfTqSFDhni8379/f0VFRVkacNSXuN1uLVq0SDfddJOuvfZaSZ0bmOV0Oju81m3vBYoPPvhAqampamxsVHh4uF577TVdffXVqqys5BpasHnzZr377rt655132r3Hz2PgutAK5NXV1R7jPRobG5Wfn6/PPvtM4eHhmjZtml566SWPn50vv/xS99xzj7755htFR0drwoQJ2rdvn6Kjo80yq1atUlBQkDIzMz0WK7PCr0II4CvZ2dn68MMP201hQ+dcddVVqqysVH19vf7yl78oKytLZWVlvq6WXzl69Kh++ctfqqSkpN30SvQiPnp2TE5OjnJycjp8b/fu3R6vb775Zn388cfnPd/mzZsv+JmhoaEqLCw85/jDzvCr7piuDMCBp7brdL5rGBsb226g7+nTp/Xtt98G5HXOycnRtm3b9Oabb2ro0KHm/s4MzIqNje3wWre9FyiCg4N1+eWXa+zYsSooKFBycrLWrFnDNbSgoqJCJ06c0PXXX6/+/furf//+Kisr05NPPqn+/fsrJiaGa9kL+KI7xp/5VQgJDg7W2LFjVVpaau5zu90qLS1VamqqD2vmPxITExUbG+txDV0ul/bv329ew9TUVNXV1amiosIss2vXLrndbqWkpPR4nX3FMAzl5OTotdde065du5SYmOjx/tixY3XRRRd5XMtDhw6purra41p+8MEHHqGupKREERERuvrqq3vmi/RCbrdbTU1NXEMLpkyZog8++ECVlZXmNm7cOM2aNcv8M9cS/sbvumNyc3OVlZWlcePGafz48Vq9erXHABxIp06dMqdRSWcGo1ZWVioqKkrDhg3TokWL9Nhjj+mKK65QYmKifvvb3yo+Pl4zZsyQJI0aNUpTp07VvHnztG7dOrW0tCgnJ0d333234uPjffStel52drY2bdqkv/3tbxowYIDZZx4ZGamwsDCPgVlRUVGKiIjQwoULPQZm3Xrrrbr66qv1b//2b1q5cqWcTqfy8/OVnZ0dME83zcvLU0ZGhoYNG6aTJ09q06ZN2r17t9544w2uoQUDBgwwxyO1ueSSSzRo0CBzP9eyF3AbZzZvjg8gfhdCLjQAB9KBAwc0efJk83Vubq4kKSsrS0VFRVqyZIkaGho0f/581dXVacKECSouLvboZ964caNycnI0ZcoUc+DRk08+2ePfxZfWrl0rSZo0aZLH/vXr1+v++++XdOGBWf369dO2bdv04IMPKjU1VZdccomysrK0YsWKnvoaPnfixAndd999qqmpUWRkpEaPHq033nhD//Iv/yKJa2gnrmUv4KMxIf6KB9gBAOCltgfY/T9pj3r9ALu3di6z9AA7f+Z3LSEAAPRWDnk3uNRhW038AyEEAAC7GMaZzZvjA4hfzY4BAAB9By0hAADYxNu1PgJtnRBCCAAAdmF2jCWEEAAAbOIwDDm8GNfhzbH+iDEhAADAJ2gJAQDALu5/bt4cH0AIIQAA2ITuGGvojgEAAD5BSwgAAHZhdowlhBAAAOzCiqmW0B0DAAB8gpYQAABswoqp1hBCAACwC90xltAdAwAAfIKWEAAAbOJwn9m8OT6QEEIAALAL3TGWEEIAALAL64RYwpgQAADgE7SEAABgE54dYw0hBAAAuzAmxBK6YwAAgE/QEgIAgF0MSd5Msw2shhBCCAAAdmFMiDV0xwAAAJ+gJQQAALsY8nJgqm018QuEEAAA7MLsGEvojgEAAD5BSwgAAHZxS3J4eXwAoSUEAACbtM2O8WbrisLCQg0fPlyhoaFKSUnR22+/fc6yLS0tWrFihZKSkhQaGqrk5GQVFxd7lCkoKNANN9ygAQMGaMiQIZoxY4YOHTrkUWbSpElyOBwe24IFCyzVmxACAIBd2saEeLNZ9PLLLys3N1fLli3Tu+++q+TkZKWnp+vEiRMdls/Pz9ezzz6rp556Sh9//LEWLFigmTNn6r333jPLlJWVKTs7W/v27VNJSYlaWlp06623qqGhweNc8+bNU01NjbmtXLnSUt0dhhFgo2AAALCZy+VSZGSkplzz7+rfL6TL5znd2qTSj/6g+vp6RUREdOqYlJQU3XDDDXr66aclSW63WwkJCVq4cKEeeeSRduXj4+P1m9/8RtnZ2ea+zMxMhYWFacOGDR1+xldffaUhQ4aorKxMEydOlHSmJWTMmDFavXq1xW/5A1pCAACwi00tIS6Xy2Nramrq8OOam5tVUVGhtLQ0c19QUJDS0tJUXl7e4TFNTU0KDQ312BcWFqa9e/ee82vV19dLkqKiojz2b9y4UYMHD9a1116rvLw8fffddxe+RmchhAAAYBebQkhCQoIiIyPNraCgoMOP+/rrr9Xa2qqYmBiP/TExMXI6nR0ek56erieeeEKffvqp3G63SkpK9Oqrr6qmpqbD8m63W4sWLdJNN92ka6+91tx/7733asOGDXrzzTeVl5enl156Sb/4xS8sXS5mxwAA0MscPXrUozsmJKTrXTw/tmbNGs2bN08jR46Uw+FQUlKSZs+erRdeeKHD8tnZ2frwww/btZTMnz/f/PN1112nuLg4TZkyRUeOHFFSUlKn6kJLCAAAdnHbsEmKiIjw2M4VQgYPHqx+/fqptrbWY39tba1iY2M7PCY6Olpbt25VQ0ODvvjiCx08eFDh4eEaMWJEu7I5OTnatm2b3nzzTQ0dOvS8Xz0lJUWSdPjw4fOWOxshBAAAm/T0FN3g4GCNHTtWpaWl5j63263S0lKlpqae99jQ0FBdeumlOn36tP7617/q9ttvN98zDEM5OTl67bXXtGvXLiUmJl6wLpWVlZKkuLi4Ttef7hgAAPxYbm6usrKyNG7cOI0fP16rV69WQ0ODZs+eLUm67777dOmll5rjSvbv369jx45pzJgxOnbsmJYvXy63260lS5aY58zOztamTZv0t7/9TQMGDDDHl0RGRiosLExHjhzRpk2bNG3aNA0aNEjvv/++Fi9erIkTJ2r06NGdrjshBAAAu/jg2TF33XWXvvrqKy1dulROp1NjxoxRcXGxOVi1urpaQUE/dHw0NjYqPz9fn332mcLDwzVt2jS99NJLGjhwoFlm7dq1ks5Mwz3b+vXrdf/99ys4OFg7d+40A09CQoIyMzOVn59vqe6sEwIAgJfa1glJS1rk9TohO4+strROiD9jTAgAAPAJumMAALCLD7pj/BkhBAAA23gZQkQIAQAAXUFLiCWMCQEAAD5BSwgAAHZxG/KqS8UdWC0hhBAAAOxiuM9s3hwfQOiOAQAAPkFLCAAAdmFgqiWEEAAA7MKYEEvojgEAAD5BSwgAAHahO8YSQggAAHYx5GUIsa0mfoHuGAAA4BO0hAAAYBe6YywhhAAAYBe3W5IXC465A2uxMkIIAAB2oSXEEsaEAAAAn6AlBAAAu9ASYgkhBAAAu7BiqiV0xwAAAJ+gJQQAAJsYhluG0fUZLt4c648IIQAA2MUwvOtSCbAxIXTHAAAAn6AlBAAAuxheDkwNsJYQQggAAHZxuyWHF+M6AmxMCN0xAADAJ2gJAQDALnTHWEIIAQDAJobbLcOL7him6AIAgK6hJcQSxoQAAACfoCUEAAC7uA3JQUtIZxFCAACwi2FI8maKbmCFELpjAACAT9ASAgCATQy3IcOL7hgjwFpCCCEAANjFcMu77pjAmqJLdwwAAH6usLBQw4cPV2hoqFJSUvT222+fs2xLS4tWrFihpKQkhYaGKjk5WcXFxZbP2djYqOzsbA0aNEjh4eHKzMxUbW2tpXoTQgAAsInhNrzerHr55ZeVm5urZcuW6d1331VycrLS09N14sSJDsvn5+fr2Wef1VNPPaWPP/5YCxYs0MyZM/Xee+9ZOufixYv1+uuva8uWLSorK9Px48d1xx13WKq7wwi0DigAAGzmcrkUGRmpCZqm/rqoy+c5rRbt1Q4dPXpUERER5v6QkBCFhIR0eExKSopuuOEGPf3005Ikt9uthIQELVy4UI888ki78vHx8frNb36j7Oxsc19mZqbCwsK0YcOGTp2zvr5e0dHR2rRpk37+859Lkg4ePKhRo0apvLxcN954Y6e+L2NCAADwUnBwsGJjY7XXucPrc4WHhyshIcFj37Jly7R8+fJ2ZZubm1VRUaG8vDxzX1BQkNLS0lReXt7h+ZuamhQaGuqxLywsTHv37u30OSsqKtTS0qK0tDSzzMiRIzVs2DBCCAAAPSk0NFRVVVVqbm72+lyGYcjhcHjsO1cryNdff63W1lbFxMR47I+JidHBgwc7PCY9PV1PPPGEJk6cqKSkJJWWlurVV19Va2trp8/pdDoVHBysgQMHtivjdDo7/V0JIQAA2CA0NLRdC0NvtGbNGs2bN08jR46Uw+FQUlKSZs+erRdeeKHH68LAVAAA/NTgwYPVr1+/drNSamtrFRsb2+Ex0dHR2rp1qxoaGvTFF1/o4MGDCg8P14gRIzp9ztjYWDU3N6uurq7Tn9sRQggAAH4qODhYY8eOVWlpqbnP7XartLRUqamp5z02NDRUl156qU6fPq2//vWvuv322zt9zrFjx+qiiy7yKHPo0CFVV1df8HPPRncMAAB+LDc3V1lZWRo3bpzGjx+v1atXq6GhQbNnz5Yk3Xfffbr00ktVUFAgSdq/f7+OHTumMWPG6NixY1q+fLncbreWLFnS6XNGRkZq7ty5ys3NVVRUlCIiIrRw4UKlpqZ2elCqRAgBAMCv3XXXXfrqq6+0dOlSOZ1OjRkzRsXFxebA0urqagUF/dDx0djYqPz8fH322WcKDw/XtGnT9NJLL3kMMr3QOSVp1apVCgoKUmZmppqampSenq5nnnnGUt1ZJwQAAPgEY0IAAIBPEEIAAIBPEEIAAIBPEEIAAIBPEEIAAIBPEEIAAIBPEEIAAIBPEEIAAIBPEEIAAIBPEEIAAIBPEEIAAIBP/P9X0uFv0vTWcAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## renaming the coordinates fro matching the code"
      ],
      "metadata": {
        "id": "LXcvLYc9XzpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_surf      = data_surf.rename({'y': 'lat', 'x': 'lon'})\n",
        "data_isl_mask = data_isl_mask.rename({'y': 'lat', 'x': 'lon'})\n",
        "\n",
        "time_ = data_surf['time'].data\n",
        "lon = data_surf['lon'].data\n",
        "lat = data_surf['lat'].data"
      ],
      "metadata": {
        "id": "viOMSUiTMn8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing the data"
      ],
      "metadata": {
        "id": "fqrKqrt9ory2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## script"
      ],
      "metadata": {
        "id": "Sv12Hk7qDdtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TrainingItem = namedtuple('TrainingItem', ['input', 'tgt'])\n",
        "\n",
        "def compute_rmse(predicted, target, masks):\n",
        "    valid_mask = masks\n",
        "    valid_predictions = predicted[valid_mask.bool()]\n",
        "    valid_targets = target[valid_mask.bool()]\n",
        "    mse = torch.nanmean((valid_targets - valid_predictions) ** 2)\n",
        "    return torch.sqrt(mse)\n",
        "\n",
        "def compute_re(predicted, target, masks):\n",
        "    valid_mask = masks\n",
        "    valid_predictions = predicted[valid_mask.bool()]\n",
        "    valid_targets = target[valid_mask.bool()]\n",
        "    epsilon = 1e-8  # Small constant to avoid division by zero\n",
        "    re = torch.nanmean(torch.abs(10**valid_targets - 10**valid_predictions) / (10**valid_targets + epsilon)) * 100\n",
        "    return re\n",
        "\n",
        "class XrDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    torch Dataset based on an xarray.DataArray with on the fly slicing.\n",
        "    ### Usage: ####\n",
        "    If you want to be able to reconstruct the input\n",
        "\n",
        "    the input xr.DataArray should:\n",
        "        - have coordinates\n",
        "        - have the last dims correspond to the patch dims in same order\n",
        "        - have for each dim of patch_dim (size(dim) - patch_dim(dim)) divisible by stride(dim)\n",
        "\n",
        "    the batches passed to self.reconstruct should:\n",
        "        - have the last dims correspond to the patch dims in same order\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self, da, patch_dims, domain_limits=None, strides=None,\n",
        "            check_full_scan=False, check_dim_order=False,\n",
        "            postpro_fn=None\n",
        "            ):\n",
        "        \"\"\"\n",
        "        da: xarray.DataArray with patch dims at the end in the dim orders\n",
        "        patch_dims: dict of da dimension to size of a patch\n",
        "        domain_limits: dict of da dimension to slices of domain to select for patch extractions\n",
        "        strides: dict of dims to stride size (default to one)\n",
        "        check_full_scan: Boolean: if True raise an error if the whole domain is not scanned by the patch size stride combination\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.return_coords = False\n",
        "        self.postpro_fn = postpro_fn\n",
        "        self.da = da.sel(**(domain_limits or {}))\n",
        "        self.patch_dims = patch_dims\n",
        "        self.strides = strides or {}\n",
        "        da_dims = dict(zip(self.da.dims, self.da.shape))\n",
        "        self.ds_size = {\n",
        "            dim: max((da_dims[dim] - patch_dims[dim]) // self.strides.get(dim, 1) + 1, 0)\n",
        "            for dim in patch_dims\n",
        "        }\n",
        "\n",
        "\n",
        "        if check_full_scan:\n",
        "            for dim in patch_dims:\n",
        "                if (da_dims[dim] - self.patch_dims[dim]) % self.strides.get(dim, 1) != 0:\n",
        "                    raise IncompleteScanConfiguration(\n",
        "                        f\"\"\"\n",
        "                        Incomplete scan in dimension dim {dim}:\n",
        "                        dataarray shape on this dim {da_dims[dim]}\n",
        "                        patch_size along this dim {self.patch_dims[dim]}\n",
        "                        stride along this dim {self.strides.get(dim, 1)}\n",
        "                        [shape - patch_size] should be divisible by stride\n",
        "                        \"\"\"\n",
        "                    )\n",
        "\n",
        "        if check_dim_order:\n",
        "            for dim in patch_dims:\n",
        "                if not '#'.join(da.dims).endswith('#'.join(list(patch_dims))):\n",
        "                    raise DangerousDimOrdering(\n",
        "                        f\"\"\"\n",
        "                        input dataarray's dims should end with patch_dims\n",
        "                        dataarray's dim {da.dims}:\n",
        "                        patch_dims {list(patch_dims)}\n",
        "                        \"\"\"\n",
        "                )\n",
        "    def __len__(self):\n",
        "        size = 1\n",
        "        for v in self.ds_size.values():\n",
        "            size *= v\n",
        "        return size\n",
        "\n",
        "    def __iter__(self):\n",
        "        for i in range(len(self)):\n",
        "            yield self[i]\n",
        "\n",
        "    def get_coords(self):\n",
        "        self.return_coords = True\n",
        "        coords = []\n",
        "        try:\n",
        "            for i in range(len(self)):\n",
        "                coords.append(self[i])\n",
        "        finally:\n",
        "            self.return_coords = False\n",
        "            return coords\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        sl = {\n",
        "                dim: slice(self.strides.get(dim, 1) * idx,\n",
        "                           self.strides.get(dim, 1) * idx + self.patch_dims[dim])\n",
        "                for dim, idx in zip(self.ds_size.keys(),\n",
        "                                    np.unravel_index(item, tuple(self.ds_size.values())))\n",
        "                }\n",
        "        item =  self.da.isel(**sl)\n",
        "\n",
        "        if self.return_coords:\n",
        "            return item.coords.to_dataset()[list(self.patch_dims)]\n",
        "\n",
        "        item = item.data.astype(np.float32)\n",
        "        if self.postpro_fn is not None:\n",
        "            return self.postpro_fn(item)\n",
        "        return item\n",
        "\n",
        "    def reconstruct(self, batches, weight=None):\n",
        "        \"\"\"\n",
        "        takes as input a list of np.ndarray of dimensions (b, *, *patch_dims)\n",
        "        return a stitched xarray.DataArray with the coords of patch_dims\n",
        "\n",
        "    batches: list of torch tensor correspondin to batches without shuffle\n",
        "        weight: tensor of size patch_dims corresponding to the weight of a prediction depending on the position on the patch (default to ones everywhere)\n",
        "        overlapping patches will be averaged with weighting\n",
        "        \"\"\"\n",
        "\n",
        "        # items = list(itertools.chain(*batches))\n",
        "        items = batches\n",
        "        return self.reconstruct_from_items(items, weight)\n",
        "\n",
        "    def reconstruct_from_items(self, items, weight=None):\n",
        "        if weight is None:\n",
        "            weight = np.ones(list(self.patch_dims.values()))\n",
        "        w = xr.DataArray(weight, dims=list(self.patch_dims.keys()))\n",
        "\n",
        "        coords = self.get_coords()\n",
        "\n",
        "        new_dims = [f'v{i}' for i in range(len(items[0].shape) - len(coords[0].dims))]\n",
        "        dims = new_dims + list(coords[0].dims)\n",
        "        das = [xr.DataArray(it, dims=dims, coords=co.coords)\n",
        "               for  it, co in zip(items, coords)]\n",
        "\n",
        "        da_shape = dict(zip(coords[0].dims, self.da.shape[-len(coords[0].dims):]))\n",
        "        new_shape = dict(zip(new_dims, items[0].shape[:len(new_dims)]))\n",
        "\n",
        "        rec_da = xr.DataArray(\n",
        "                np.zeros([*new_shape.values(), *da_shape.values()]),\n",
        "                dims=dims,\n",
        "                coords={d: self.da[d] for d in self.patch_dims}\n",
        "        )\n",
        "        count_da = xr.zeros_like(rec_da)\n",
        "\n",
        "        for da in das:\n",
        "            rec_da.loc[da.coords] = rec_da.sel(da.coords) + da * w\n",
        "            count_da.loc[da.coords] = count_da.sel(da.coords) + w\n",
        "\n",
        "        return rec_da / count_da\n",
        "\n",
        "class XrConcatDataset(torch.utils.data.ConcatDataset):\n",
        "    \"\"\"\n",
        "    Concatenation of XrDatasets\n",
        "    \"\"\"\n",
        "    def reconstruct(self, batches, weight=None):\n",
        "        \"\"\"\n",
        "        Returns list of xarray object, reconstructed from batches\n",
        "        \"\"\"\n",
        "        items_iter = itertools.chain(*batches)\n",
        "        rec_das = []\n",
        "        for ds in self.datasets:\n",
        "            ds_items = list(itertools.islice(items_iter, len(ds)))\n",
        "            rec_das.append(ds.reconstruct_from_items(ds_items, weight))\n",
        "\n",
        "        return rec_das\n",
        "\n",
        "class AugmentedDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, inp_ds, aug_factor, aug_only=False, noise_sigma=None):\n",
        "        self.aug_factor = aug_factor\n",
        "        self.aug_only = aug_only\n",
        "        self.inp_ds = inp_ds\n",
        "        self.perm = np.random.permutation(len(self.inp_ds))\n",
        "        self.noise_sigma = noise_sigma\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inp_ds) * (1 + self.aug_factor - int(self.aug_only))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.aug_only:\n",
        "            idx = idx + len(self.inp_ds)\n",
        "\n",
        "        if idx < len(self.inp_ds):\n",
        "            return self.inp_ds[idx]\n",
        "\n",
        "        tgt_idx = idx % len(self.inp_ds)\n",
        "        perm_idx = tgt_idx\n",
        "        for _ in range(idx // len(self.inp_ds)):\n",
        "            perm_idx = self.perm[perm_idx]\n",
        "\n",
        "        item = self.inp_ds[tgt_idx]\n",
        "        perm_item = self.inp_ds[perm_idx]\n",
        "\n",
        "        noise = np.zeros_like(item.input, dtype=np.float32)\n",
        "        if self.noise_sigma is not None:\n",
        "            noise = np.random.randn(*item.input.shape).astype(np.float32) * self.noise_sigma\n",
        "\n",
        "        return item._replace(input=noise + np.where(np.isfinite(perm_item.input),\n",
        "                             item.tgt, np.full_like(item.tgt,np.nan)))\n",
        "\n",
        "# DataModule Class\n",
        "class BaseDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, input_da, domains, xrds_kw, dl_kw, aug_kw=None, norm_stats=None, **kwargs):\n",
        "        super().__init__()\n",
        "        self.input_da = input_da\n",
        "        print(\"input_da shape\", input_da.shape)\n",
        "        self.domains = domains\n",
        "        self.xrds_kw = xrds_kw\n",
        "        self.dl_kw = dl_kw\n",
        "        self.aug_kw = aug_kw if aug_kw is not None else {}\n",
        "        self._norm_stats = norm_stats\n",
        "\n",
        "        self.train_ds = None\n",
        "        self.val_ds = None\n",
        "        self.test_ds = None\n",
        "        self._post_fn = None\n",
        "\n",
        "    # Add other methods and functions from BaseDataModule as per your train.py file\n",
        "    def norm_stats(self):\n",
        "        if self._norm_stats is None:\n",
        "            self._norm_stats = self.train_mean_std()\n",
        "            print(\"Norm stats\", self._norm_stats)\n",
        "        return self._norm_stats\n",
        "\n",
        "    def train_mean_std(self, variable=\"tgt\"):\n",
        "        train_data = self.input_da.sel(self.xrds_kw.get(\"domain_limits\", {})).sel(\n",
        "            self.domains[\"train\"]\n",
        "        )\n",
        "        return train_data.sel(variable=variable).pipe(\n",
        "            lambda da: (da.mean().values.item(), da.std().values.item())\n",
        "        )\n",
        "\n",
        "    def post_fn(self):\n",
        "        m, s = self.norm_stats()\n",
        "        normalize = lambda item: (item - m) / s\n",
        "        return ft.partial(\n",
        "            ft.reduce,\n",
        "            lambda i, f: f(i),\n",
        "            [\n",
        "                TrainingItem._make,\n",
        "                lambda item: item._replace(tgt=normalize(item.tgt)),\n",
        "                lambda item: item._replace(input=normalize(item.input)),\n",
        "            ],\n",
        "        )\n",
        "\n",
        "    def post_fn_rand(self):\n",
        "        m, s = self.norm_stats()\n",
        "        normalize = lambda item: (item - m) / s\n",
        "        return ft.partial(\n",
        "            ft.reduce,\n",
        "            lambda i, f: f(i),\n",
        "            [\n",
        "                TrainingItem._make,\n",
        "                lambda item: item._replace(tgt=normalize(item.tgt)),\n",
        "                lambda item: item._replace(input=self.rand_obs(normalize(item.tgt))),\n",
        "            ],\n",
        "        )\n",
        "\n",
        "    def rand_obs(self, gt_item):  # to generate random observations ONLINE\n",
        "        obs_mask_item = ~np.isnan(gt_item)\n",
        "        _obs_item = gt_item\n",
        "        dtime = self.xrds_kw['patch_dims']['time']\n",
        "        dlat = self.xrds_kw['patch_dims']['lat']\n",
        "        dlon = self.xrds_kw['patch_dims']['lon']\n",
        "        for t_ in range(dtime):\n",
        "            obs_mask_item_t_ = obs_mask_item[t_]\n",
        "            if np.sum(obs_mask_item_t_) > 0.25 * dlat * dlon:\n",
        "                obs_obj = 0.5 * np.sum(obs_mask_item_t_)\n",
        "                while np.sum(obs_mask_item_t_) >= obs_obj:\n",
        "                    half_patch_height = np.random.randint(2, 10)\n",
        "                    half_patch_width = np.random.randint(2, 10)\n",
        "                    idx_lat = np.random.randint(0, dlat)\n",
        "                    idx_lon = np.random.randint(0, dlon)\n",
        "                    obs_mask_item_t_[\n",
        "                        np.max([0, idx_lat - half_patch_height]) : np.min(\n",
        "                            [dlat, idx_lat + half_patch_height + 1]\n",
        "                        ),\n",
        "                        np.max([0, idx_lon - half_patch_width]) : np.min(\n",
        "                            [dlon, idx_lon + half_patch_width + 1]\n",
        "                        ),\n",
        "                    ] = 0\n",
        "                #print(np.sum(obs_mask_item_t_))\n",
        "                obs_mask_item[t_] = obs_mask_item_t_\n",
        "        obs_mask_item = obs_mask_item == 1\n",
        "        obs_item = np.where(obs_mask_item, _obs_item, np.nan)\n",
        "        return obs_item\n",
        "\n",
        "    def setup(self, stage=\"test\"): ## In the OSSE setup, we apply the mask on all the datasets\n",
        "        train_data = self.input_da.sel(self.domains[\"train\"])\n",
        "        post_fn_rand = self.post_fn_rand()\n",
        "        self.train_ds = XrDataset(\n",
        "            train_data,\n",
        "            **self.xrds_kw,\n",
        "            postpro_fn=post_fn_rand,\n",
        "            # post_fn_rand is used only for training\n",
        "        )\n",
        "        if self.aug_kw:\n",
        "            self.train_ds = AugmentedDataset(self.train_ds, **self.aug_kw)\n",
        "\n",
        "        # post_fn = self.post_fn()\n",
        "        self.val_ds = XrDataset(\n",
        "            self.input_da.sel(self.domains[\"val\"]),\n",
        "            **self.xrds_kw,\n",
        "            postpro_fn=post_fn_rand,\n",
        "        )\n",
        "        self.test_ds = XrDataset(\n",
        "            self.input_da.sel(self.domains[\"test\"]),\n",
        "            **self.xrds_kw,\n",
        "            postpro_fn=post_fn_rand,\n",
        "        )\n",
        "\n",
        "    def masked_train_ds(self):\n",
        "        return self.train_ds\n",
        "\n",
        "    def masked_val_ds(self):\n",
        "        return self.val_ds\n",
        "\n",
        "    def masked_test_ds(self):\n",
        "        return self.test_ds\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(self.train_ds, shuffle=True, **self.dl_kw)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(self.val_ds, shuffle=False, **self.dl_kw)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(self.test_ds, shuffle=False, **self.dl_kw)\n",
        "\n",
        "class ConcatDataModule(BaseDataModule):\n",
        "    def train_mean_std(self):\n",
        "        sum, count = 0, 0\n",
        "        train_data = self.input_da.sel(self.xrds_kw.get('domain_limits', {}))\n",
        "        for domain in self.domains['train']:\n",
        "            _sum, _count = train_data.sel(domain).sel(variable='tgt').pipe(lambda da: (da.sum(), da.pipe(np.isfinite).sum()))\n",
        "            sum += _sum\n",
        "            count += _count\n",
        "\n",
        "        mean = sum / count\n",
        "        sum = 0\n",
        "        for domain in self.domains['train']:\n",
        "            _sum = train_data.sel(domain).sel(variable='tgt').pipe(lambda da: da - mean).pipe(np.square).sum()\n",
        "            sum += _sum\n",
        "        std = (sum / count)**0.5\n",
        "        return mean.values.item(), std.values.item()\n",
        "\n",
        "    def setup(self, stage='test'):\n",
        "        post_fn = self.post_fn()\n",
        "        self.train_ds = XrConcatDataset([\n",
        "            XrDataset(self.input_da.sel(domain), **self.xrds_kw, postpro_fn=post_fn,)\n",
        "            for domain in self.domains['train']\n",
        "        ])\n",
        "        if self.aug_factor >= 1:\n",
        "            self.train_ds = AugmentedDataset(self.train_ds, **self.aug_kw)\n",
        "\n",
        "        self.val_ds = XrConcatDataset([\n",
        "            XrDataset(self.input_da.sel(domain), **self.xrds_kw, postpro_fn=post_fn,)\n",
        "            for domain in self.domains['val']\n",
        "        ])\n",
        "        self.test_ds = XrConcatDataset([\n",
        "            XrDataset(self.input_da.sel(domain), **self.xrds_kw, postpro_fn=post_fn,)\n",
        "            for domain in self.domains['test']\n",
        "        ])\n",
        "\n",
        "\n",
        "class RandValDataModule(BaseDataModule):\n",
        "    def __init__(self, val_prop, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.val_prop = val_prop\n",
        "\n",
        "    def setup(self, stage='test'):\n",
        "        post_fn = self.post_fn()\n",
        "        train_ds = XrDataset(self.input_da.sel(self.domains['train']), **self.xrds_kw, postpro_fn=post_fn,)\n",
        "        n_val = int(self.val_prop * len(train_ds))\n",
        "        n_train = len(train_ds) - n_val\n",
        "        self.train_ds, self.val_ds = torch.utils.data.random_split(train_ds, [n_train, n_val])\n",
        "\n",
        "        if self.aug_factor > 1:\n",
        "            self.train_ds = AugmentedDataset(self.train_ds, **self.aug_kw)\n",
        "\n",
        "        self.test_ds = XrDataset(self.input_da.sel(self.domains['test']), **self.xrds_kw, postpro_fn=post_fn,)\n",
        "\n",
        "\n",
        "def load_bbp_data (GT,patch):\n",
        "    GT = GT.rename({'SPM': 'GT'})#bbp443 here before\n",
        "    merg=xr.merge([GT,patch])\n",
        "    return (\n",
        "        merg\n",
        "        .load()\n",
        "        .assign(\n",
        "            input=lambda ds: ds.SPM,\n",
        "            tgt=lambda ds: ds.GT,\n",
        "        )[['input', 'tgt']]\n",
        "        .transpose(\"time\", \"lat\", \"lon\")\n",
        "        .to_array()\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "sFs-qG-VCQ7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## preparing the dataloader"
      ],
      "metadata": {
        "id": "qRwu7DhU4B4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## new dataloader\n",
        "input_da = load_bbp_data(GT=data_isl_mask, patch=data_isl_mask)\n",
        "\n",
        "\n",
        "# Configuration parameters from base.yaml\n",
        "config = {\n",
        "    'input_da': input_da,\n",
        "    'domains': {\n",
        "        'train': {'time': slice('2016-01-01', '2016-12-31')},\n",
        "        'val': {'time': slice('2017-01-01', '2017-06-30')},\n",
        "        'test': {'time': slice('2017-07-01', '2018-01-01')}\n",
        "    },\n",
        "    'xrds_kw': {\n",
        "        'patch_dims': {'time': 7, 'lat': 200, 'lon': 482},\n",
        "        'strides': {'time': 1, 'lat': 200, 'lon': 482}\n",
        "    },\n",
        "    'dl_kw': {'batch_size': 4, 'num_workers': 1},\n",
        "    'aug_factor': 1,\n",
        "    'aug_only': True\n",
        "}\n",
        "\n",
        "# Instantiate the DataModule with the configuration\n",
        "data_module = BaseDataModule(**config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-KD-hlK3-zE",
        "outputId": "7032666b-03ed-4f02-af79-eeff6ac7b602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_da shape (2, 732, 200, 482)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pre-processing the data and creating the datasets"
      ],
      "metadata": {
        "id": "W4SpzogByChr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setup the data module\n",
        "data_module.setup()\n",
        "\n",
        "meanTr, stdTr = data_module.norm_stats()\n",
        "\n",
        "# Access the datasets\n",
        "train_dataloader = data_module.train_dataloader()\n",
        "val_dataloader = data_module.val_dataloader()\n",
        "test_dataloader = data_module.test_dataloader()\n",
        "\n",
        "## create the dataloader\n",
        "dataloaders = {\n",
        "    'train': train_dataloader,\n",
        "    'val': val_dataloader\n",
        "}\n",
        "\n",
        "dataset_sizes = {'train': len(train_dataloader), 'val': len(val_dataloader)}"
      ],
      "metadata": {
        "id": "7RMUkYFz-yH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd4995a5-2467-4903-f463-7b16e7e65e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm stats (1.0178498126906828, 0.6091843922474393)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = data_module.masked_train_ds()\n",
        "eval_ds  = data_module.masked_val_ds()\n",
        "test_ds  = data_module.masked_test_ds()"
      ],
      "metadata": {
        "id": "Fw49E5QKfGSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define and load the AE model"
      ],
      "metadata": {
        "id": "_dXyErziDhUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DimAE = 32\n",
        "downsamp = None\n",
        "dim_in = config['xrds_kw']['patch_dims']['time']"
      ],
      "metadata": {
        "id": "haj4QHRkDgpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "  def __init__(self, dim_in, dim_hidden, kernel_size=3, downsamp=None, bilin_quad = True):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.bilin_quad = bilin_quad\n",
        "\n",
        "    self.conv_in = torch.nn.Conv2d(\n",
        "        dim_in, dim_hidden, kernel_size = kernel_size, padding=kernel_size // 2\n",
        "    )\n",
        "\n",
        "    self.conv_hidden = torch.nn.Conv2d(\n",
        "        dim_hidden, dim_hidden, kernel_size=kernel_size, padding=kernel_size // 2,\n",
        "    )\n",
        "\n",
        "    self.bilin_1 = torch.nn.Conv2d(\n",
        "        dim_hidden, dim_hidden, kernel_size=kernel_size, padding=kernel_size // 2,\n",
        "    )\n",
        "\n",
        "    self.bilin_21 = torch.nn.Conv2d(\n",
        "        dim_hidden, dim_hidden, kernel_size=kernel_size, padding=kernel_size // 2,\n",
        "    )\n",
        "\n",
        "    self.bilin_22 = torch.nn.Conv2d(\n",
        "        dim_hidden, dim_hidden, kernel_size=kernel_size, padding=kernel_size // 2,\n",
        "    )\n",
        "\n",
        "    self.conv_out = torch.nn.Conv2d(\n",
        "        2 * dim_hidden, dim_in, kernel_size=kernel_size, padding=kernel_size // 2,\n",
        "    )\n",
        "\n",
        "    self.down = torch.nn.AvgPool2d(downsamp) if downsamp is not None else torch.nn.Identity()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.down( x )\n",
        "    # x = x.permute(1,0,2,3)\n",
        "    # print(x.shape)\n",
        "    x = self.conv_in( x )\n",
        "    x = self.conv_hidden(F.relu(x))\n",
        "\n",
        "    nonlin = self.bilin_21(x)**2 if self.bilin_quad else (self.bilin_21(x)*self.bilin_22(x))\n",
        "    x = self.conv_out(\n",
        "        torch.cat([self.bilin_1(x), nonlin], dim=1)\n",
        "    )\n",
        "\n",
        "    # x = x.permute(1,0,2,3)\n",
        "    return(x)\n",
        "\n",
        "\n",
        "class Decoder(torch.nn.Module):\n",
        "  def __init__(self, downsamp = None):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.up = (torch.nn.UpsamplingBilinear2d(scale_factor=downsamp) if downsamp is not None else torch.nn.Identity())\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.up( x )\n",
        "    return x\n",
        "\n",
        "class model_AE(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(model_AE, self).__init__()\n",
        "    self.encoder = Encoder(dim_in = dim_in, dim_hidden=DimAE, downsamp=downsamp)\n",
        "    self.decoder = Decoder(downsamp = downsamp)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = self.decoder(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "CBtZXE2MLWoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## load the model\n",
        "ModelAE = model_AE()\n",
        "print(ModelAE)\n",
        "print(sum(p.numel() for p in ModelAE.parameters() if p.requires_grad))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "ModelAE = ModelAE.to(device)"
      ],
      "metadata": {
        "id": "NZbIHemXtyd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48cd2773-09db-464a-dfb9-7092e9ae79e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_AE(\n",
            "  (encoder): Encoder(\n",
            "    (conv_in): Conv2d(7, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv_hidden): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bilin_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bilin_21): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bilin_22): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv_out): Conv2d(64, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (down): Identity()\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (up): Identity()\n",
            "  )\n",
            ")\n",
            "43079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Torch.nn.module is a base class for all the neural network modules\n",
        "\n",
        "## class for the creation of the Residual Neural Network\n",
        "class ResNetConv2D(torch.nn.Module):\n",
        "  def __init__(self,Nblocks,dim,K,\n",
        "                 kernel_size,\n",
        "                 padding=0):\n",
        "      super(ResNetConv2D, self).__init__()\n",
        "      self.resnet = self._make_ResNet(Nblocks,dim,K,kernel_size,padding)\n",
        "\n",
        "\n",
        "  # classic structure of a resnet block\n",
        "  def _make_ResNet(self,Nblocks,dim,K,kernel_size,padding):\n",
        "      layers = []\n",
        "      for kk in range(0,Nblocks):\n",
        "        layers.append(torch.nn.Conv2d(dim,K*dim,kernel_size,padding=padding,bias=False))\n",
        "        layers.append(torch.nn.ReLU())\n",
        "        layers.append(torch.nn.Conv2d(K*dim,dim,kernel_size,padding=padding,bias=False))\n",
        "\n",
        "      return torch.nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.resnet ( x )\n",
        "\n",
        "      return x\n",
        "\n",
        "## class for the LSTM architecture\n",
        "class ConvLSTM2d(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, kernel_size = 3):\n",
        "        super(ConvLSTM2d, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.kernel_size = kernel_size\n",
        "        self.padding = int((kernel_size - 1) / 2)\n",
        "        self.Gates = torch.nn.Conv2d(input_size + hidden_size, 4 * hidden_size, kernel_size = self.kernel_size, stride = 1, padding = self.padding)\n",
        "\n",
        "    def forward(self, input_, prev_state):\n",
        "\n",
        "        # get batch and spatial sizes\n",
        "        batch_size = input_.shape[0]\n",
        "        spatial_size = input_.shape[2:]\n",
        "\n",
        "        # generate empty prev_state, if None is provided\n",
        "        if prev_state is None:\n",
        "            state_size = [batch_size, self.hidden_size] + list(spatial_size)\n",
        "            prev_state = (\n",
        "                torch.autograd.Variable(torch.zeros(state_size)).to(device),\n",
        "                torch.autograd.Variable(torch.zeros(state_size)).to(device)\n",
        "            )\n",
        "\n",
        "        # prev_state has two components\n",
        "        prev_hidden, prev_cell = prev_state\n",
        "\n",
        "        stacked_inputs = torch.cat((input_, prev_hidden), 1)\n",
        "        gates = self.Gates(stacked_inputs)\n",
        "\n",
        "        # chunk across channel dimension: split it to 4 samples at dimension 1\n",
        "        in_gate, remember_gate, out_gate, cell_gate = gates.chunk(4, 1)\n",
        "\n",
        "        # apply sigmoid non linearity\n",
        "        in_gate = torch.sigmoid(in_gate)\n",
        "        remember_gate = torch.sigmoid(remember_gate)\n",
        "        out_gate = torch.sigmoid(out_gate)\n",
        "\n",
        "        # apply tanh non linearity\n",
        "        cell_gate = torch.tanh(cell_gate)\n",
        "\n",
        "        # compute current cell and hidden state\n",
        "        cell = (remember_gate * prev_cell) + (in_gate * cell_gate)\n",
        "        hidden = out_gate * torch.tanh(cell)\n",
        "\n",
        "        return hidden, cell\n",
        "\n",
        "## class for computing the gradient of the loss function (modified respect to the original code)\n",
        "class Compute_Grad(torch.nn.Module):\n",
        "    def __init__(self,ShapeData,):\n",
        "        super(Compute_Grad, self).__init__()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.shape     = ShapeData\n",
        "\n",
        "        self.alphaObs    = torch.nn.Parameter(torch.Tensor([1.]))\n",
        "        self.alphaAE     = torch.nn.Parameter(torch.Tensor([1.]))\n",
        "\n",
        "    def forward(self, x,xpred,xobs,mask):\n",
        "\n",
        "        # compute gradient\n",
        "        ## true gradient using autograd for prior ||x-g(x)||\n",
        "        loss1 = F.mse_loss(x, xpred)\n",
        "        loss2 = F.mse_loss(x*mask, xobs*mask)\n",
        "        loss  = self.alphaAE**2 * loss1 + self.alphaObs**2 * loss2 ## variational cost\n",
        "\n",
        "        grad = torch.autograd.grad(loss,x,create_graph=True)[0]\n",
        "\n",
        "        # Check is this is needed or not\n",
        "        grad.retain_grad()\n",
        "\n",
        "        return grad\n",
        "\n",
        "# Gradient-based minimization using a LSTM using a (sub)gradient as inputs\n",
        "class model_GradUpdate(torch.nn.Module):\n",
        "    def __init__(self,ShapeData,periodicBnd=False):\n",
        "        super(model_GradUpdate, self).__init__()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.shape     = ShapeData\n",
        "            self.DimState = 48\n",
        "            # self.DimState  = 5*self.shape[0]\n",
        "            self.PeriodicBnd = periodicBnd\n",
        "            if( (self.PeriodicBnd == True) & (len(self.shape) == 2) ):\n",
        "                print('No periodic boundary available for FxTime (eg, L63) tensors. Forced to False')\n",
        "                self.PeriodicBnd = False\n",
        "        self.compute_Grad  = Compute_Grad(ShapeData)\n",
        "        self.convLayer     = self._make_ConvGrad()\n",
        "\n",
        "        K = torch.Tensor([0.1]).view(1,1,1,1)\n",
        "        self.convLayer.weight = torch.nn.Parameter(K)\n",
        "        self.lstm = ConvLSTM2d(self.shape[1],self.DimState,3)\n",
        "\n",
        "    def _make_ConvGrad(self):\n",
        "        layers = []\n",
        "        layers.append(torch.nn.Conv2d(self.DimState, self.shape[1], (1,1), padding=0,bias=False))\n",
        "\n",
        "        return torch.nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x,xpred,xobs,mask,hidden,cell,gradnorm=1.0):\n",
        "\n",
        "        # compute gradient\n",
        "        grad = self.compute_Grad(x, xpred,xobs,mask)\n",
        "        grad  = grad / gradnorm\n",
        "\n",
        "        if self.PeriodicBnd == True :\n",
        "            dB     = 7\n",
        "            #\n",
        "            grad_  = torch.cat((grad[:,:,x.size(2)-dB:,:],grad,grad[:,:,0:dB,:]),dim=2)\n",
        "            if hidden is None:\n",
        "                hidden_,cell_ = self.lstm(grad_,None)\n",
        "            else:\n",
        "                hidden_  = torch.cat((hidden[:,:,x.size(2)-dB:,:],hidden,hidden[:,:,0:dB,:]),dim=2)\n",
        "                cell_    = torch.cat((cell[:,:,x.size(2)-dB:,:],cell,cell[:,:,0:dB,:]),dim=2)\n",
        "                hidden_,cell_ = self.lstm(grad_,[hidden_,cell_])\n",
        "\n",
        "            hidden = hidden_[:,:,dB:x.size(2)+dB,:]\n",
        "            cell   = cell_[:,:,dB:x.size(2)+dB,:]\n",
        "        else:\n",
        "            if hidden is None:\n",
        "                hidden,cell = self.lstm(grad,None)\n",
        "            else:\n",
        "                hidden,cell = self.lstm(grad,[hidden,cell])\n",
        "\n",
        "        grad = self.convLayer( hidden )\n",
        "\n",
        "        return grad,hidden,cell\n",
        "\n",
        "class Model_4DVarNN_GradFP(torch.nn.Module):\n",
        "    def __init__(self,mod_AE,ShapeData,NiterProjection,NiterGrad, lr_grad=0.2, InterpFlag=False,periodicBnd=False):\n",
        "        super(Model_4DVarNN_GradFP, self).__init__()\n",
        "\n",
        "        self.model_AE = mod_AE\n",
        "        self.lr_grad = lr_grad\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # print('Opitm type %d'%OptimType)\n",
        "            self.NProjFP   = int(NiterProjection)\n",
        "            self.NGrad     = int(NiterGrad)\n",
        "            self.InterpFlag  = InterpFlag\n",
        "            self.periodicBnd = periodicBnd\n",
        "\n",
        "        ## load the updating rule using gradient descent\n",
        "        self.model_Grad = model_GradUpdate(ShapeData)\n",
        "\n",
        "    def forward(self, x_inp,xobs,mask,g1=None,g2=None,normgrad=0.0):\n",
        "        mask_  = torch.add(1.0,torch.mul(mask,-1.0)) #1. - mask\n",
        "\n",
        "        x      = torch.mul(x_inp,1.0)\n",
        "\n",
        "        # fixed-point iterations\n",
        "        if self.NProjFP > 0:\n",
        "          for kk in range(0,self.NProjFP):\n",
        "        #if NiterProjection > 0:\n",
        "        #  x      = torch.mul(x_inp,1.0)\n",
        "        #  for kk in range(0,NiterProjection):\n",
        "            x_proj = self.model_AE(x)\n",
        "            x_proj = torch.mul(x_proj,mask_)\n",
        "            x      = torch.mul(x, mask)\n",
        "            x      = torch.add(x , x_proj )\n",
        "\n",
        "        # gradient iteration\n",
        "        if self.NGrad > 0:\n",
        "            # gradient normalisation\n",
        "            grad     = self.model_Grad.compute_Grad(x, self.model_AE(x),xobs,mask)\n",
        "            ## true gradient used by Quentin\n",
        "            true_grad = grad\n",
        "            if normgrad == 0. :\n",
        "                _normgrad = torch.sqrt( torch.mean( grad**2 ) )\n",
        "            else:\n",
        "                _normgrad = normgrad\n",
        "            for kk in range(0,self.NGrad):\n",
        "                # AE pediction\n",
        "                xpred = self.model_AE(x)\n",
        "\n",
        "                # gradient update\n",
        "                if kk == 0:\n",
        "                  grad,hidden,cell  = self.model_Grad( x, xpred, xobs, mask, g1, g2 , _normgrad )\n",
        "                else:\n",
        "                  grad,hidden,cell  = self.model_Grad( x, xpred, xobs, mask, hidden, cell , _normgrad )\n",
        "\n",
        "                # optimization update\n",
        "                step_update = (1 / (kk + 1))*grad + self.lr_grad*((kk + 1) / self.NGrad)*true_grad\n",
        "                x = x - step_update\n",
        "\n",
        "            return x,hidden,cell,_normgrad\n",
        "        else:\n",
        "            _normgrad = 1.\n",
        "            return x,None,None,_normgrad\n"
      ],
      "metadata": {
        "id": "zhvKzOjLgzoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning of 4DVarNet"
      ],
      "metadata": {
        "id": "u_6ZyvTzZrsh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model definition (LSTM)"
      ],
      "metadata": {
        "id": "QqT2ZQcugvlc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model learning"
      ],
      "metadata": {
        "id": "_Or_g_cAz3Mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UsePriodicBoundary = True # use a periodic boundary for all conv operators in the gradient model (see torch_4DVarNN_dinAE)\n",
        "InterpFlag         = False\n",
        "\n",
        "tr_loss_list =[]\n",
        "val_loss_list = []\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "patch_size = 7\n",
        "batch_size = 4\n",
        "lat = data_isl_mask['lat']\n",
        "lon = data_isl_mask['lon']\n",
        "shapeData = np.array((batch_size, patch_size, len(lat), len(lon)))\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "alpha          = np.array([1.,0.1])\n",
        "num_epochs     = 4000\n",
        "\n",
        "IterUpdate     = [0,100,200,500,2000,1000,1200]#[0,2,4,6,9,15]\n",
        "NbProjection   = [0,0,0,0,0,0,0]#[0,0,0,0,0,0]#[5,5,5,5,5]##\n",
        "NbGradIter     = [10,10,20,20,20,20,20]#[0,0,1,2,3,3]#[0,2,2,4,5,5]#\n",
        "lrUpdate       = [1e-3,1e-4,1e-4,1e-5,1e-5,1e-4,1e-5,1e-6,1e-7]\n",
        "\n",
        "NBGradCurrent   = NbGradIter[0]\n",
        "NBProjCurrent   = NbProjection[0]\n",
        "lrCurrent       = lrUpdate[0]\n",
        "\n",
        "model           = Model_4DVarNN_GradFP(ModelAE,shapeData,NBProjCurrent,NBGradCurrent,UsePriodicBoundary)\n",
        "modelSave       = Model_4DVarNN_GradFP(ModelAE,shapeData,NBProjCurrent,NBGradCurrent,UsePriodicBoundary)\n",
        "model           = model.to(device)\n",
        "print('4DVar model: Number of trainable parameters = %d'%(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
        "\n",
        "flagLoadModel   = 0\n",
        "\n",
        "# fileAEModelInit = 'xxxx'\n",
        "\n",
        "# optimization setting: freeze or not the AE\n",
        "lambda_LRAE = 0.5\n",
        "optimizer   = optim.Adam([{'params': model.model_Grad.parameters()},\n",
        "                        {'params': model.model_AE.encoder.parameters(), 'lr': lambda_LRAE*lrCurrent}\n",
        "                        ], lr=lrCurrent)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_MIfNnrz46c",
        "outputId": "3d7d6e71-f47a-4852-c6e1-079dda8184c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4DVar model: Number of trainable parameters = 138650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training function for dinAE\n",
        "since = time.time()\n",
        "\n",
        "alpha_Grad = alpha[0]\n",
        "alpha_AE   = alpha[1]\n",
        "\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "best_loss = 1e10\n",
        "\n",
        "num_epochs  = 5\n",
        "comptUpdate = 1\n",
        "iterInit    = 0\n",
        "\n",
        "for epoch in range(iterInit,num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    if ( epoch == IterUpdate[comptUpdate] ) & ( epoch > 0 ):\n",
        "        # update GradFP parameters\n",
        "        NBProjCurrent = NbProjection[comptUpdate]\n",
        "        NBGradCurrent = NbGradIter[comptUpdate]\n",
        "        lrCurrent     = lrUpdate[comptUpdate]\n",
        "\n",
        "        if( (NBProjCurrent != NbProjection[comptUpdate-1]) | (NBGradCurrent != NbGradIter[comptUpdate-1]) ):\n",
        "            print(\"..... \")\n",
        "            print(\"..... \")\n",
        "            print(\"..... Update/initialize number of projections/Graditer in GradCOnvAE model # %d/%d\"%(NbProjection[comptUpdate],NbGradIter[comptUpdate]))\n",
        "\n",
        "            # update GradFP architectures\n",
        "            print('..... Update model architecture')\n",
        "            print(\"..... \")\n",
        "            model = Model_4DVarNN_GradFP(model_AE,shapeData,NBProjCurrent,NBGradCurrent,UsePriodicBoundary)\n",
        "            model = model.to(device)\n",
        "\n",
        "            # copy model parameters from current model\n",
        "            model.load_state_dict(best_model_wts)\n",
        "\n",
        "            optimizer        = optim.Adam([{'params': model.model_Grad.parameters()},\n",
        "                                    {'params': model.model_AE.encoder.parameters(), 'lr': lambda_LRAE*lrCurrent}\n",
        "                                    ], lr=lrCurrent)\n",
        "\n",
        "        else:\n",
        "            # update optimizer learning rate\n",
        "            print('..... Update learning rate')\n",
        "            mm = 0\n",
        "            lr = np.array([lrCurrent,lambda_LRAE*lrCurrent])\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr[mm]\n",
        "                mm += 1\n",
        "\n",
        "        # update counter\n",
        "        if comptUpdate < len(IterUpdate)-1:\n",
        "            comptUpdate += 1\n",
        "\n",
        "    # Each epoch has a training and validation phase\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model.train()\n",
        "        else:\n",
        "            torch.cuda.empty_cache()\n",
        "            model.eval()\n",
        "\n",
        "        running_loss         = 0.0\n",
        "        running_loss_All     = 0.\n",
        "        running_loss_AE      = 0.\n",
        "        num_loss             = 0\n",
        "        RMSE = 0.\n",
        "        RE = 0.\n",
        "\n",
        "        # Iterate over data.\n",
        "\n",
        "        for state, target in tqdm(dataloaders[phase]):\n",
        "            masks = torch.isnan(state).float()\n",
        "            state = torch.nan_to_num(state)\n",
        "            target = torch.nan_to_num(target)\n",
        "\n",
        "            state      = state.to(device)\n",
        "            masks      = masks.to(device)\n",
        "            target     = target.to(device)\n",
        "            inv_masks = 1. - masks\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # need to evaluate grad/backward during the evaluation and training phase for model_AE\n",
        "            with torch.set_grad_enabled(True):\n",
        "                state = torch.autograd.Variable(state, requires_grad=True)\n",
        "\n",
        "                ## LSTM\n",
        "                outputs,hidden_new,cell_new,normgrad = model(state,target,inv_masks,None,None)\n",
        "\n",
        "                loss_All    =  F.mse_loss(outputs, target)\n",
        "                loss_AE     =  F.mse_loss(model.model_AE(outputs), outputs)#torch.mean((model.model_AE(outputs) - outputs)**2 )\n",
        "                loss_AE_GT  =  F.mse_loss(model.model_AE(target), target)\n",
        "                RMSE_batch = compute_rmse(outputs, target, masks)\n",
        "                RE_batch = compute_re(outputs, target, masks)\n",
        "                # print(loss_All.item(), loss_AE.item(), loss_AE_GT.item())\n",
        "\n",
        "                loss  = alpha_Grad * loss_All + 0.5 * alpha_AE * ( loss_AE + loss_AE_GT )\n",
        "\n",
        "                # backward + optimize only if in training phase\n",
        "                if( phase == 'train' ):\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "\n",
        "            running_loss               += loss.item() * state.size(0)\n",
        "            running_loss_All           += loss_All.item() * state.size(0)\n",
        "            running_loss_AE            += loss_AE_GT.item() * state.size(0)\n",
        "            num_loss                   += state.size(0)\n",
        "            RMSE                       += RMSE_batch.item() * state.size(0)\n",
        "            RE                         += RE_batch.item() * state.size(0)\n",
        "\n",
        "            torch.cuda.empty_cache() ## clear the memory\n",
        "\n",
        "\n",
        "        epoch_loss       = running_loss / num_loss\n",
        "        epoch_loss_All   = running_loss_All / num_loss\n",
        "        epoch_loss_AE    = running_loss_AE / num_loss\n",
        "        RMSE             = RMSE / num_loss\n",
        "        RE               = RE / num_loss\n",
        "\n",
        "        epoch_loss_All = epoch_loss_All * stdTr**2\n",
        "        epoch_loss_AE  = epoch_loss_AE * stdTr**2\n",
        "\n",
        "\n",
        "        if phase == 'train':\n",
        "          tr_loss_list.append(epoch_loss)\n",
        "        else:\n",
        "          val_loss_list.append(epoch_loss)\n",
        "\n",
        "        print('{} Loss: {:.5e} RMSE: {:.5e} RE: {:.5e} LossAll: {:.5e} LossAE: {:.5e}' .format(\n",
        "            phase, epoch_loss, RMSE, RE, epoch_loss_All, epoch_loss_AE),flush=True)\n",
        "        #print('... F %f'%model.model_AE.encoder.F)\n",
        "\n",
        "        # deep copy the model\n",
        "        if phase == 'val' and epoch_loss < best_loss:\n",
        "            best_loss      = epoch_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "time_elapsed = time.time() - since\n",
        "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "    time_elapsed // 60, time_elapsed % 60))\n",
        "print('Best val loss: {:4f}'.format(best_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "DhKb14-p0QOF",
        "outputId": "8f5c4601-d7cf-430a-aafb-f1c1a5426888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/4\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [03:44<00:00,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 2.97220e-01 RMSE: 5.05456e-01 RE: 1.17569e+03 LossAll: 1.03401e-01 LossAE: 5.48770e-02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  2%|▏         | 1/44 [00:03<02:51,  3.98s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 15.77 GiB of which 66.38 MiB is free. Process 40687 has 15.71 GiB memory in use. Of the allocated memory 14.98 GiB is allocated by PyTorch, and 353.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-2e41f740ccef>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;31m## LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minv_masks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mloss_All\u001b[0m    \u001b[0;34m=\u001b[0m  \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-ed164f6098aa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_inp, xobs, mask, g1, g2, normgrad)\u001b[0m\n\u001b[1;32m    204\u001b[0m                   \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_Grad\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg2\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0m_normgrad\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                   \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_Grad\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0m_normgrad\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;31m# optimization update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-ed164f6098aa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xpred, xobs, mask, hidden, cell, gradnorm)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvLayer\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-ed164f6098aa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, prev_state)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprev_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mstacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mgates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 15.77 GiB of which 66.38 MiB is free. Process 40687 has 15.71 GiB memory in use. Of the allocated memory 14.98 GiB is allocated by PyTorch, and 353.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(tr_loss_list, label=\"Train\")\n",
        "plt.plot(val_loss_list, label='Validation')\n",
        "plt.xlabel(\"Epoch n.\")\n",
        "plt.ylabel(\"Loss value\")\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_cD5roTS6ZJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), r'/content/drive/MyDrive/Material for Master thesis/best_model_try_islands_mask.pt')"
      ],
      "metadata": {
        "id": "X5aeR6RyeG8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of the model"
      ],
      "metadata": {
        "id": "TEdvOt-dwx2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## create the dataloader\n",
        "dataloaders = {\n",
        "    'train': train_dataloader,\n",
        "    'test': test_dataloader\n",
        "}\n",
        "\n",
        "dataset_sizes = {'train': len(train_dataloader), 'test': len(test_dataloader)}"
      ],
      "metadata": {
        "id": "jXpZrEKq7AIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model           = Model_4DVarNN_GradFP(ModelAE,shapeData,NBProjCurrent,NBGradCurrent,UsePriodicBoundary)\n",
        "model.load_state_dict(torch.load(r'/content/drive/MyDrive/Material for Master thesis/best_model_try.pt')) ## loading the model\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "print(\".... Device GPU: \"+str(torch.cuda.is_available()))\n",
        "model = model.to(device)\n",
        "\n",
        "alpha4DVar = np.array([0.01,0.99])\n",
        "y_train = []  ##create empty lists for appending the outputs\n",
        "y_test  = []  ##create empty lists for appending the outputs\n",
        "\n",
        "for phase in ['train', 'test']:\n",
        "  since = time.time()\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  running_loss         = 0.\n",
        "  running_loss_All     = 0.\n",
        "  running_loss_AE      = 0.\n",
        "  num_loss             = 0\n",
        "  RMSE = 0.\n",
        "  RE = 0.\n",
        "\n",
        "  for state, target in tqdm(dataloaders[phase]):\n",
        "      masks = torch.isnan(state).float()\n",
        "      state = torch.nan_to_num(state)\n",
        "      target = torch.nan_to_num(target)\n",
        "\n",
        "      state      = state.to(device)\n",
        "      masks      = masks.to(device)\n",
        "      target     = target.to(device)\n",
        "\n",
        "\n",
        "      with torch.set_grad_enabled(True):\n",
        "        state = torch.autograd.Variable(state, requires_grad = True)\n",
        "\n",
        "        outputs, hidden_new, new, _ = model(state, target, (1. - masks), None, None)\n",
        "        if phase == 'train':\n",
        "          y_train.append(outputs.cpu().detach().numpy().squeeze()*stdTr + meanTr)\n",
        "        else:\n",
        "          y_test.append(outputs.cpu().detach().numpy().squeeze()*stdTr + meanTr)\n",
        "\n",
        "        loss_All    =  F.mse_loss(outputs, target)\n",
        "        loss_AE     =  F.mse_loss(model.model_AE(outputs), outputs)\n",
        "        loss_AE_GT  =  F.mse_loss(model.model_AE(target), target)\n",
        "        RMSE_batch  =  compute_rmse(outputs, target, masks)\n",
        "        RE_batch    =  compute_re(outputs, target, masks)\n",
        "\n",
        "      running_loss_All           += loss_All.item() * state.size(0)\n",
        "      running_loss_AE            += loss_AE_GT.item() * state.size(0)\n",
        "      num_loss                   += state.size(0)\n",
        "      RMSE                       += RMSE_batch.item() * state.size(0)\n",
        "      RE                         += RE_batch.item() * state.size(0)\n",
        "\n",
        "      torch.cuda.empty_cache() ## clear the memory\n",
        "\n",
        "  epoch_loss_All   = running_loss_All / num_loss\n",
        "  epoch_loss_AE    = running_loss_AE / num_loss\n",
        "  RMSE             = RMSE / num_loss\n",
        "  RE               = RE / num_loss\n",
        "\n",
        "  epoch_loss_All = epoch_loss_All * stdTr**2\n",
        "  epoch_loss_AE  = epoch_loss_AE * stdTr**2\n",
        "\n",
        "  print('{} RMSE: {:.5e} RE: {:.5e} LossAll: {:.5e} LossAE: {:.5e}' .format(\n",
        "    phase, RMSE, RE, epoch_loss_All, epoch_loss_AE),flush=True)\n",
        "\n",
        "  time_elapsed = time.time() - since\n",
        "  print('Eval. time in {:.0f}m {:.0f}s'.format(\n",
        "      time_elapsed // 60, time_elapsed % 60))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfGiNPwkxvVa",
        "outputId": "d35853d9-b1ea-4035-c62c-89b4d2ebccd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".... Device GPU: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [02:10<00:00,  1.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train RMSE: 2.76090e-01 RE: 2.57569e+02 LossAll: 2.54752e-02 LossAE: 2.21204e-02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval. time in 2m 10s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 45/45 [01:04<00:00,  1.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test RMSE: 2.83916e-01 RE: 2.67537e+02 LossAll: 2.71217e-02 LossAE: 2.18614e-02\n",
            "Eval. time in 1m 5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = np.concatenate(y_test, axis = 0)"
      ],
      "metadata": {
        "id": "vAB99weD8RTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(r'/content/drive/MyDrive/Material for Master thesis/DATA/y_pred.npy', y_test)"
      ],
      "metadata": {
        "id": "fq4DfzkK_f9u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}